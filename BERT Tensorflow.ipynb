{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from tensorflow import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6194197965567352402, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14742444489581862372\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 907751022919386053\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 32039642727\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8611099686685878167\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import multiprocessing\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'toxic_model'\n",
    "TRAIN_DATA_FILES_PATTERN = 'data/processed/train-*.tsv'\n",
    "VALID_DATA_FILES_PATTERN = 'data/processed/valid-*.tsv'\n",
    "RESUME_TRAINING = True\n",
    "MULTI_THREADING = True\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "CLASS_TO_LABEL = {'toxic': 0, 'non-toxic': 1}\n",
    "BERT_PRETRAINED_DIR = '/home/luis.magana/BERT/uncased_L-12_H-768_A-12/'\n",
    "TARGET_LABELS = ['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 42\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Set the output directory for saving model file\n",
    "# Optionally, set a GCP bucket location\n",
    "OUTPUT_DIR = './toxic_models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 220\n",
    "PAD_WORD = '#=KS=#'\n",
    "HEADER_DEFAULTS = [['NA'], ['NA'], ['NA']]\n",
    "TARGET_NAME = 'target'\n",
    "WEIGHT_COLUNM_NAME = 'weight' #This will not be used for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('https://s3.amazonaws.com/ccwf-ml-data/jigsaw/test.csv')\n",
    "train_df = pd.read_csv('https://s3.amazonaws.com/ccwf-ml-data/jigsaw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "train_df['target'] = train_df['target'].apply(lambda x: 0 if x <= 0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_isolate = '.,?!-;*\"â€¦:â€”()%#$&_/@ï¼¼ãƒ»Ï‰+=â€â€œ[]^â€“>\\\\Â°<~â€¢â‰ â„¢ËˆÊŠÉ’âˆžÂ§{}Â·Ï„Î±â¤â˜ºÉ¡|Â¢â†’Ì¶`â¥â”â”£â”«â”—ï¼¯â–ºâ˜…Â©â€•Éªâœ”Â®\\x96\\x92â—Â£â™¥âž¤Â´Â¹â˜•â‰ˆÃ·â™¡â—â•‘â–¬â€²É”Ëâ‚¬Û©Ûžâ€ Î¼âœ’âž¥â•â˜†ËŒâ—„Â½Ê»Ï€Î´Î·Î»ÏƒÎµÏÎ½Êƒâœ¬ï¼³ï¼µï¼°ï¼¥ï¼²ï¼©ï¼´â˜»Â±â™ÂµÂºÂ¾âœ“â—¾ØŸï¼Žâ¬…â„…Â»Ð’Ð°Ð²â£â‹…Â¿Â¬â™«ï¼£ï¼­Î²â–ˆâ–“â–’â–‘â‡’â­â€ºÂ¡â‚‚â‚ƒâ§â–°â–”â—žâ–€â–‚â–ƒâ–„â–…â–†â–‡â†™Î³Ì„â€³â˜¹âž¡Â«Ï†â…“â€žâœ‹ï¼šÂ¥Ì²Ì…Ìâˆ™â€›â—‡âœâ–·â“â—Â¶ËšË™ï¼‰ÑÐ¸Ê¿âœ¨ã€‚É‘\\x80â—•ï¼ï¼…Â¯âˆ’ï¬‚ï¬â‚Â²ÊŒÂ¼â´â„â‚„âŒ â™­âœ˜â•ªâ–¶â˜­âœ­â™ªâ˜”â˜ â™‚â˜ƒâ˜ŽâœˆâœŒâœ°â†â˜™â—‹â€£âš“å¹´âˆŽâ„’â–ªâ–™â˜â…›ï½ƒï½ï½“Ç€â„®Â¸ï½—â€šâˆ¼â€–â„³â„â†â˜¼â‹†Ê’âŠ‚ã€â…”Â¨Í¡à¹âš¾âš½Î¦Ã—Î¸ï¿¦ï¼Ÿï¼ˆâ„ƒâ©â˜®âš æœˆâœŠâŒâ­•â–¸â– â‡Œâ˜â˜‘âš¡â˜„Ç«â•­âˆ©â•®ï¼Œä¾‹ï¼žÊ•ÉÌ£Î”â‚€âœžâ”ˆâ•±â•²â–â–•â”ƒâ•°â–Šâ–‹â•¯â”³â”Šâ‰¥â˜’â†‘â˜É¹âœ…â˜›â™©â˜žï¼¡ï¼ªï¼¢â—”â—¡â†“â™€â¬†Ì±â„\\x91â €Ë¤â•šâ†ºâ‡¤âˆâœ¾â—¦â™¬Â³ã®ï½œï¼âˆµâˆ´âˆšÎ©Â¤â˜œâ–²â†³â–«â€¿â¬‡âœ§ï½ï½–ï½ï¼ï¼’ï¼ï¼˜ï¼‡â€°â‰¤âˆ•Ë†âšœâ˜'\n",
    "symbols_to_delete = '\\nðŸ•\\rðŸµðŸ˜‘\\xa0\\ue014\\t\\uf818\\uf04a\\xadðŸ˜¢ðŸ¶ï¸\\uf0e0ðŸ˜œðŸ˜ŽðŸ‘Š\\u200b\\u200eðŸ˜Ø¹Ø¯ÙˆÙŠÙ‡ØµÙ‚Ø£Ù†Ø§Ø®Ù„Ù‰Ø¨Ù…ØºØ±ðŸ˜ðŸ’–ðŸ’µÐ•ðŸ‘ŽðŸ˜€ðŸ˜‚\\u202a\\u202cðŸ”¥ðŸ˜„ðŸ»ðŸ’¥á´ÊÊ€á´‡É´á´…á´á´€á´‹Êœá´œÊŸá´›á´„á´˜Ê™Ò“á´Šá´¡É¢ðŸ˜‹ðŸ‘×©×œ×•××‘×™ðŸ˜±â€¼\\x81ã‚¨ãƒ³ã‚¸æ•…éšœ\\u2009ðŸšŒá´µÍžðŸŒŸðŸ˜ŠðŸ˜³ðŸ˜§ðŸ™€ðŸ˜ðŸ˜•\\u200fðŸ‘ðŸ˜®ðŸ˜ƒðŸ˜˜××¢×›×—ðŸ’©ðŸ’¯â›½ðŸš„ðŸ¼à®œðŸ˜–á´ ðŸš²â€ðŸ˜ŸðŸ˜ˆðŸ’ªðŸ™ðŸŽ¯ðŸŒ¹ðŸ˜‡ðŸ’”ðŸ˜¡\\x7fðŸ‘Œá¼á½¶Î®Î¹á½²Îºá¼€Î¯á¿ƒá¼´Î¾ðŸ™„ï¼¨ðŸ˜ \\ufeff\\u2028ðŸ˜‰ðŸ˜¤â›ºðŸ™‚\\u3000ØªØ­ÙƒØ³Ø©ðŸ‘®ðŸ’™ÙØ²Ø·ðŸ˜ðŸ¾ðŸŽ‰ðŸ˜ž\\u2008ðŸ¾ðŸ˜…ðŸ˜­ðŸ‘»ðŸ˜¥ðŸ˜”ðŸ˜“ðŸ½ðŸŽ†ðŸ»ðŸ½ðŸŽ¶ðŸŒºðŸ¤”ðŸ˜ª\\x08â€‘ðŸ°ðŸ‡ðŸ±ðŸ™†ðŸ˜¨ðŸ™ƒðŸ’•ð˜Šð˜¦ð˜³ð˜¢ð˜µð˜°ð˜¤ð˜ºð˜´ð˜ªð˜§ð˜®ð˜£ðŸ’—ðŸ’šåœ°ç„è°·ÑƒÐ»ÐºÐ½ÐŸÐ¾ÐÐðŸ¾ðŸ•ðŸ˜†×”ðŸ”—ðŸš½æ­Œèˆžä¼ŽðŸ™ˆðŸ˜´ðŸ¿ðŸ¤—ðŸ‡ºðŸ‡¸Ð¼Ï…Ñ‚Ñ•â¤µðŸ†ðŸŽƒðŸ˜©\\u200aðŸŒ ðŸŸðŸ’«ðŸ’°ðŸ’ŽÑÐ¿Ñ€Ð´\\x95ðŸ–ðŸ™…â›²ðŸ°ðŸ¤ðŸ‘†ðŸ™Œ\\u2002ðŸ’›ðŸ™ðŸ‘€ðŸ™ŠðŸ™‰\\u2004Ë¢áµ’Ê³Ê¸á´¼á´·á´ºÊ·áµ—Ê°áµ‰áµ˜\\x13ðŸš¬ðŸ¤“\\ue602ðŸ˜µÎ¬Î¿ÏŒÏ‚Î­á½¸×ª×ž×“×£× ×¨×š×¦×˜ðŸ˜’ÍðŸ†•ðŸ‘…ðŸ‘¥ðŸ‘„ðŸ”„ðŸ”¤ðŸ‘‰ðŸ‘¤ðŸ‘¶ðŸ‘²ðŸ”›ðŸŽ“\\uf0b7\\uf04c\\x9f\\x10æˆéƒ½ðŸ˜£âºðŸ˜ŒðŸ¤‘ðŸŒðŸ˜¯ÐµÑ…ðŸ˜²á¼¸á¾¶á½ðŸ’žðŸš“ðŸ””ðŸ“šðŸ€ðŸ‘\\u202dðŸ’¤ðŸ‡\\ue613å°åœŸè±†ðŸ¡â”â‰\\u202fðŸ‘ ã€‹à¤•à¤°à¥à¤®à¤¾ðŸ‡¹ðŸ‡¼ðŸŒ¸è”¡è‹±æ–‡ðŸŒžðŸŽ²ãƒ¬ã‚¯ã‚µã‚¹ðŸ˜›å¤–å›½äººå…³ç³»Ð¡Ð±ðŸ’‹ðŸ’€ðŸŽ„ðŸ’œðŸ¤¢ÙÙŽÑŒÑ‹Ð³Ñä¸æ˜¯\\x9c\\x9dðŸ—‘\\u2005ðŸ’ƒðŸ“£ðŸ‘¿à¼¼ã¤à¼½ðŸ˜°á¸·Ð—Ð·â–±Ñ†ï¿¼ðŸ¤£å–æ¸©å“¥åŽè®®ä¼šä¸‹é™ä½ å¤±åŽ»æ‰€æœ‰çš„é’±åŠ æ‹¿å¤§åç¨Žéª—å­ðŸãƒ„ðŸŽ…\\x85ðŸºØ¢Ø¥Ø´Ø¡ðŸŽµðŸŒŽÍŸá¼”æ²¹åˆ«å…‹ðŸ¤¡ðŸ¤¥ðŸ˜¬ðŸ¤§Ð¹\\u2003ðŸš€ðŸ¤´Ê²ÑˆÑ‡Ð˜ÐžÐ Ð¤Ð”Ð¯ÐœÑŽÐ¶ðŸ˜ðŸ–‘á½á½»Ïç‰¹æ®Šä½œæˆ¦ç¾¤Ñ‰ðŸ’¨åœ†æ˜Žå›­×§â„ðŸˆðŸ˜ºðŸŒâá»‡ðŸ”ðŸ®ðŸðŸ†ðŸ‘ðŸŒ®ðŸŒ¯ðŸ¤¦\\u200dð“’ð“²ð“¿ð“µì•ˆì˜í•˜ì„¸ìš”Ð–Ñ™ÐšÑ›ðŸ€ðŸ˜«ðŸ¤¤á¿¦æˆ‘å‡ºç”Ÿåœ¨äº†å¯ä»¥è¯´æ™®é€šè¯æ±‰è¯­å¥½æžðŸŽ¼ðŸ•ºðŸ¸ðŸ¥‚ðŸ—½ðŸŽ‡ðŸŽŠðŸ†˜ðŸ¤ ðŸ‘©ðŸ–’ðŸšªå¤©ä¸€å®¶âš²\\u2006âš­âš†â¬­â¬¯â–æ–°âœ€â•ŒðŸ‡«ðŸ‡·ðŸ‡©ðŸ‡ªðŸ‡®ðŸ‡¬ðŸ‡§ðŸ˜·ðŸ‡¨ðŸ‡¦Ð¥Ð¨ðŸŒ\\x1fæ€é¸¡ç»™çŒ´çœ‹Êð—ªð—µð—²ð—»ð˜†ð—¼ð˜‚ð—¿ð—®ð—¹ð—¶ð˜‡ð—¯ð˜ð—°ð˜€ð˜…ð—½ð˜„ð—±ðŸ“ºÏ–\\u2000Ò¯Õ½á´¦áŽ¥Ò»Íº\\u2007Õ°\\u2001É©ï½™ï½…àµ¦ï½ŒÆ½ï½ˆð“ð¡ðžð«ð®ððšðƒðœð©ð­ð¢ð¨ð§Æ„á´¨×Ÿá‘¯à»Î¤á§à¯¦Ð†á´‘Üð¬ð°ð²ð›ð¦ð¯ð‘ð™ð£ð‡ð‚ð˜ðŸŽÔœÐ¢á—žà±¦ã€”áŽ«ð³ð”ð±ðŸ”ðŸ“ð…ðŸ‹ï¬ƒðŸ’˜ðŸ’“Ñ‘ð˜¥ð˜¯ð˜¶ðŸ’ðŸŒ‹ðŸŒ„ðŸŒ…ð™¬ð™–ð™¨ð™¤ð™£ð™¡ð™®ð™˜ð™ ð™šð™™ð™œð™§ð™¥ð™©ð™ªð™—ð™žð™ð™›ðŸ‘ºðŸ·â„‹ð€ð¥ðªðŸš¶ð™¢á¼¹ðŸ¤˜Í¦ðŸ’¸Ø¬íŒ¨í‹°ï¼·ð™‡áµ»ðŸ‘‚ðŸ‘ƒÉœðŸŽ«\\uf0a7Ð‘Ð£Ñ–ðŸš¢ðŸš‚àª—à«àªœàª°àª¾àª¤à«€á¿†ðŸƒð“¬ð“»ð“´ð“®ð“½ð“¼â˜˜ï´¾Ì¯ï´¿â‚½\\ue807ð‘»ð’†ð’ð’•ð’‰ð’“ð’–ð’‚ð’ð’…ð’”ð’Žð’—ð’ŠðŸ‘½ðŸ˜™\\u200cÐ›â€’ðŸŽ¾ðŸ‘¹âŽŒðŸ’â›¸å…¬å¯“å…»å® ç‰©å—ðŸ„ðŸ€ðŸš‘ðŸ¤·æ“ç¾Žð’‘ð’šð’ð‘´ðŸ¤™ðŸ’æ¬¢è¿Žæ¥åˆ°é˜¿æ‹‰æ–¯×¡×¤ð™«ðŸˆð’Œð™Šð™­ð™†ð™‹ð™ð˜¼ð™…ï·»ðŸ¦„å·¨æ”¶èµ¢å¾—ç™½é¬¼æ„¤æ€’è¦ä¹°é¢áº½ðŸš—ðŸ³ðŸðŸðŸ–ðŸ‘ðŸ•ð’„ðŸ—ð ð™„ð™ƒðŸ‘‡é”Ÿæ–¤æ‹·ð—¢ðŸ³ðŸ±ðŸ¬â¦ãƒžãƒ«ãƒãƒ‹ãƒãƒ­æ ªå¼ç¤¾â›·í•œêµ­ì–´ã„¸ã…“ë‹ˆÍœÊ–ð˜¿ð™”â‚µð’©â„¯ð’¾ð“ð’¶ð“‰ð“‡ð“Šð“ƒð“ˆð“…â„´ð’»ð’½ð“€ð“Œð’¸ð“Žð™Î¶ð™Ÿð˜ƒð—ºðŸ®ðŸ­ðŸ¯ðŸ²ðŸ‘‹ðŸ¦Šå¤šä¼¦ðŸ½ðŸŽ»ðŸŽ¹â›“ðŸ¹ðŸ·ðŸ¦†ä¸ºå’Œä¸­å‹è°Šç¥è´ºä¸Žå…¶æƒ³è±¡å¯¹æ³•å¦‚ç›´æŽ¥é—®ç”¨è‡ªå·±çŒœæœ¬ä¼ æ•™å£«æ²¡ç§¯å”¯è®¤è¯†åŸºç£å¾’æ›¾ç»è®©ç›¸ä¿¡è€¶ç¨£å¤æ´»æ­»æ€ªä»–ä½†å½“ä»¬èŠäº›æ”¿æ²»é¢˜æ—¶å€™æˆ˜èƒœå› åœ£æŠŠå…¨å ‚ç»“å©šå­©ææƒ§ä¸”æ —è°“è¿™æ ·è¿˜â™¾ðŸŽ¸ðŸ¤•ðŸ¤’â›‘ðŸŽæ‰¹åˆ¤æ£€è®¨ðŸðŸ¦ðŸ™‹ðŸ˜¶ì¥ìŠ¤íƒ±íŠ¸ë¤¼ë„ì„ìœ ê°€ê²©ì¸ìƒì´ê²½ì œí™©ì„ë µê²Œë§Œë“¤ì§€ì•Šë¡ìž˜ê´€ë¦¬í•´ì•¼í•©ë‹¤ìºë‚˜ì—ì„œëŒ€ë§ˆì´ˆì™€í™”ì•½ê¸ˆì˜í’ˆëŸ°ì„±ë¶„ê°ˆë•ŒëŠ”ë°˜ë“œì‹œí—ˆëœì‚¬ìš©ðŸ”«ðŸ‘å‡¸á½°ðŸ’²ðŸ—¯ð™ˆá¼Œð’‡ð’ˆð’˜ð’ƒð‘¬ð‘¶ð•¾ð–™ð–—ð–†ð–Žð–Œð–ð–•ð–Šð–”ð–‘ð–‰ð–“ð–ð–œð–žð–šð–‡ð•¿ð–˜ð–„ð–›ð–’ð–‹ð–‚ð•´ð–Ÿð–ˆð•¸ðŸ‘‘ðŸš¿ðŸ’¡çŸ¥å½¼ç™¾\\uf005ð™€ð’›ð‘²ð‘³ð‘¾ð’‹ðŸ’ðŸ˜¦ð™’ð˜¾ð˜½ðŸð˜©ð˜¨á½¼á¹‘ð‘±ð‘¹ð‘«ð‘µð‘ªðŸ‡°ðŸ‡µðŸ‘¾á“‡á’§á”­áƒá§á¦á‘³á¨á“ƒá“‚á‘²á¸á‘­á‘Žá“€á£ðŸ„ðŸŽˆðŸ”¨ðŸŽðŸ¤žðŸ¸ðŸ’ŸðŸŽ°ðŸŒðŸ›³ç‚¹å‡»æŸ¥ç‰ˆðŸ­ð‘¥ð‘¦ð‘§ï¼®ï¼§ðŸ‘£\\uf020ã£ðŸ‰Ñ„ðŸ’­ðŸŽ¥ÎžðŸ´ðŸ‘¨ðŸ¤³ðŸ¦\\x0bðŸ©ð‘¯ð’’ðŸ˜—ðŸðŸ‚ðŸ‘³ðŸ—ðŸ•‰ðŸ²Ú†ÛŒð‘®ð—•ð—´ðŸ’êœ¥â²£â²ðŸ‘â°é‰„ãƒªäº‹ä»¶Ñ—ðŸ’Šã€Œã€\\uf203\\uf09a\\uf222\\ue608\\uf202\\uf099\\uf469\\ue607\\uf410\\ue600ç‡»è£½ã‚·è™šå½å±ç†å±ˆÐ“ð‘©ð‘°ð’€ð‘ºðŸŒ¤ð—³ð—œð—™ð—¦ð—§ðŸŠá½ºá¼ˆá¼¡Ï‡á¿–Î›â¤ðŸ‡³ð’™ÏˆÕÕ´Õ¥Õ¼Õ¡ÕµÕ«Õ¶Ö€Ö‚Õ¤Õ±å†¬è‡³á½€ð’ðŸ”¹ðŸ¤šðŸŽð‘·ðŸ‚ðŸ’…ð˜¬ð˜±ð˜¸ð˜·ð˜ð˜­ð˜“ð˜–ð˜¹ð˜²ð˜«Ú©Î’ÏŽðŸ’¢ÎœÎŸÎÎ‘Î•ðŸ‡±â™²ðˆâ†´ðŸ’’âŠ˜È»ðŸš´ðŸ–•ðŸ–¤ðŸ¥˜ðŸ“ðŸ‘ˆâž•ðŸš«ðŸŽ¨ðŸŒ‘ðŸ»ðŽððŠð‘­ðŸ¤–ðŸŽŽðŸ˜¼ðŸ•·ï½‡ï½’ï½Žï½”ï½‰ï½„ï½•ï½†ï½‚ï½‹ðŸ°ðŸ‡´ðŸ‡­ðŸ‡»ðŸ‡²ð—žð—­ð—˜ð—¤ðŸ‘¼ðŸ“‰ðŸŸðŸ¦ðŸŒˆðŸ”­ã€ŠðŸŠðŸ\\uf10aáƒšÚ¡ðŸ¦\\U0001f92f\\U0001f92aðŸ¡ðŸ’³á¼±ðŸ™‡ð—¸ð—Ÿð— ð—·ðŸ¥œã•ã‚ˆã†ãªã‚‰ðŸ”¼'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions #pip install contractions\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions.contractions_dict.keys()))\n",
    "def expand_contractions(s, contractions_dict=contractions.contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}\n",
    "\n",
    "\n",
    "def handle_punctuation(x):\n",
    "    x = x.translate(remove_dict)\n",
    "    x = x.translate(isolate_dict)\n",
    "    return x\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = expand_contractions(x)\n",
    "    return x.split(' ')\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def preprocess(x):\n",
    "    x = handle_punctuation(x)\n",
    "    x = handle_contractions(x)\n",
    "    x = fix_quote(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4656fd441e4b4857ab3c1fc42557f4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=160, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].swifter.allow_dask_on_strings(enable=True).apply(lambda x:preprocess(x))\n",
    "test_df['comment_text'] = test_df['comment_text'].swifter.allow_dask_on_strings(enable=True).apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805, 45)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410170</th>\n",
       "      <td>5842313</td>\n",
       "      <td>0</td>\n",
       "      <td>To Daniel Sage of Centennial  -  the KKK did n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370650</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803472</th>\n",
       "      <td>5103997</td>\n",
       "      <td>0</td>\n",
       "      <td>Another day ,  another WWIII advocacy piece fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>325163</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197005</th>\n",
       "      <td>5578826</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Dare \"  needs to be resigned as a non worki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>354489</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                                       comment_text  \\\n",
       "1410170  5842313       0  To Daniel Sage of Centennial  -  the KKK did n...   \n",
       "803472   5103997       0  Another day ,  another WWIII advocacy piece fr...   \n",
       "1197005  5578826       0   \" Dare \"  needs to be resigned as a non worki...   \n",
       "\n",
       "         severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "1410170              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "803472               0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "1197005              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1410170      0.0  ...      370650  approved      0    0    0      1         0   \n",
       "803472       0.0  ...      325163  rejected      0    0    0      7         0   \n",
       "1197005      0.0  ...      354489  approved      0    0    0      1         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1410170              0.0                         0                         4  \n",
       "803472               0.0                         0                         4  \n",
       "1197005              0.0                         0                         4  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.941032\n",
       "1    0.058968\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410170</th>\n",
       "      <td>5842313</td>\n",
       "      <td>0</td>\n",
       "      <td>To Daniel Sage of Centennial  -  the KKK did n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370650</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803472</th>\n",
       "      <td>5103997</td>\n",
       "      <td>0</td>\n",
       "      <td>Another day ,  another WWIII advocacy piece fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>325163</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197005</th>\n",
       "      <td>5578826</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Dare \"  needs to be resigned as a non worki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>354489</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                                       comment_text  \\\n",
       "1410170  5842313       0  To Daniel Sage of Centennial  -  the KKK did n...   \n",
       "803472   5103997       0  Another day ,  another WWIII advocacy piece fr...   \n",
       "1197005  5578826       0   \" Dare \"  needs to be resigned as a non worki...   \n",
       "\n",
       "         severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "1410170              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "803472               0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "1197005              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1410170      0.0  ...      370650  approved      0    0    0      1         0   \n",
       "803472       0.0  ...      325163  rejected      0    0    0      7         0   \n",
       "1197005      0.0  ...      354489  approved      0    0    0      1         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1410170              0.0                         0                         4  \n",
       "803472               0.0                         0                         4  \n",
       "1197005              0.0                         0                         4  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = [\"id\", \"target\", \"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import tokenization\n",
    "import os\n",
    "\n",
    "\n",
    "VOCAB_LIST_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_LIST_FILE, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5fbee29e7140b29329f9f075c1e567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=160, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_df['comment_text'] = train_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n",
    "test_df['comment_text'] = test_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa9204a33b74c5c83788e1c3c860a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=158, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_df['comment_text'] = val_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.988081\n",
       "1    0.011919\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = test_df['comment_text'].apply(lambda x: len(x.split(' ')))\n",
    "s.plot(kind='hist')\n",
    "s.apply(lambda x: 0 if x <= 220 else 1).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[HEADER]\n",
    "val_df = val_df[HEADER]\n",
    "\n",
    "train_df.to_csv('./data/processed/train-data.tsv', sep='\\t', index=False, header=False)\n",
    "val_df.to_csv('./data/processed/valid-data.tsv', sep='\\t', index=False, header=False)\n",
    "test_df.to_csv('./data/processed/test-data.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tsv_row(tsv_row):\n",
    "    \"\"\"\n",
    "    This function assumes that the text has already been cleaned and tokenized. \n",
    "    \"\"\"\n",
    "    data = tf.decode_csv(tsv_row, record_defaults=HEADER_DEFAULTS, field_delim='\\t')\n",
    "    features = dict(zip(HEADER, data))\n",
    "    target = features.pop(TARGET_NAME)\n",
    "    # giving more weight to \"spam\" records are the are only 13% of the training set\n",
    "    # features[WEIGHT_COLUNM_NAME] =  tf.cond( tf.equal(target,'spam'), lambda: 6.6, lambda: 1.0 ) \n",
    "    features[WEIGHT_COLUNM_NAME] = tf.cond(tf.equal(target, '1'), lambda: 6.6, lambda: 1.0 )\n",
    "    return features, target\n",
    "\n",
    "def parse_label(label_string_tensor):\n",
    "    \"\"\"\n",
    "    Takes a tensor string containg the labeled class and returns a one-hot vector representation.\n",
    "    \"\"\"\n",
    "    table = tf.contrib.lookup.index_table_from_tensor(tf.constant(TARGET_LABELS))\n",
    "    return table.lookup(label_string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(files_name_pattern, mode=tf.estimator.ModeKeys.EVAL, \n",
    "                 skip_header_lines=0, \n",
    "                 num_epochs=1,\n",
    "                 batch_size=200):\n",
    "    \"\"\"\n",
    "    Input Function for tensorflow estimator. Returns the tensor features and \n",
    "    one-hot representation of the target class.\n",
    "    \"\"\"\n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "    \n",
    "    num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1\n",
    "    \n",
    "    buffer_size = 2 * batch_size + 1\n",
    "   \n",
    "    print(\"\\n\", \"* data input_fn:\")\n",
    "    print(\"===========================================\")\n",
    "    print(\"Input file(s): {}\".format(files_name_pattern))\n",
    "    print(\"Batch size: {}\".format(batch_size))\n",
    "    print(\"Epoch Count: {}\".format(num_epochs))\n",
    "    print(\"Mode: {}\".format(mode))\n",
    "    print(\"Thread Count: {}\".format(num_threads))\n",
    "    print(\"Shuffle: {}\".format(shuffle))\n",
    "    print(\"===========================================\", \"\\n\")\n",
    "\n",
    "    file_names = tf.matching_files(files_name_pattern)\n",
    "    dataset = data.TextLineDataset(filenames=file_names)\n",
    "    \n",
    "    dataset = dataset.skip(skip_header_lines)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "        \n",
    "    dataset = dataset.map(lambda tsv_row: parse_tsv_row(tsv_row), \n",
    "                          num_parallel_calls=num_threads)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.prefetch(buffer_size)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, target = iterator.get_next()\n",
    "    return features, parse_label(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text_feature): \n",
    "    \"\"\"\n",
    "    The text features will be transformed into a word id vector. \n",
    "    \n",
    "    in  ---> ['a misty ridge uprises from the surge <UNK> <UNK> ... <UNK>']\n",
    "    out ---> [27 39 40 41 42  1 43  0  0 ... 0]\n",
    "    \"\"\"\n",
    "    #with tf.device(\"/device:XLA_CPU:0\"):\n",
    "    CLS = tf.fill(tf.shape(text_feature), \"[CLS]\")\n",
    "    SEP = tf.fill(tf.shape(text_feature), \"[SEP]\")   \n",
    "    text_feature = tf.strings.join([CLS, text_feature, SEP], separator=' ')\n",
    "    # Load vocabolary lookup table to map word => word_id\n",
    "    vocab_table = tf.contrib.lookup.index_table_from_file(vocabulary_file=VOCAB_LIST_FILE, \n",
    "                                                          num_oov_buckets=1, default_value=-1)\n",
    "    # Split text to words -> this will produce sparse tensor with variable-lengthes (word count) entries\n",
    "    words = tf.string_split(text_feature)\n",
    "    # Convert sparse tensor to dense tensor by padding each entry to match the longest in the batch\n",
    "    dense_words = tf.sparse_tensor_to_dense(words, default_value=PAD_WORD)\n",
    "    # Convert word to word_ids via the vocab lookup table\n",
    "    word_ids = vocab_table.lookup(dense_words)\n",
    "    # Create a word_ids padding\n",
    "    padding = tf.constant([[0,0],[0,MAX_DOCUMENT_LENGTH]])\n",
    "    # Pad all the word_ids entries to the maximum document length\n",
    "    word_ids_padded = tf.pad(word_ids, padding)\n",
    "    word_ids_padded = tf.dtypes.cast(word_ids_padded, dtype=tf.dtypes.int32)\n",
    "    word_id_vector = tf.slice(word_ids_padded, [0,0], [-1, MAX_DOCUMENT_LENGTH])\n",
    "    # Create Mask\n",
    "    input_mask = tf.where(word_id_vector > 0, tf.ones_like(word_id_vector, \n",
    "                                                           dtype=tf.dtypes.int32), word_id_vector)\n",
    "    # Create Seg IDs\n",
    "    segment_ids = tf.zeros(tf.shape(input_mask), dtype=tf.dtypes.int32)\n",
    "    # Return the final word_id_vector\n",
    "    return word_id_vector, input_mask, segment_ids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#mat = np.array([2,3,4,5,0,0,0,0], dtype=np.int32)\n",
    "#tf_mat = tf.constant(mat)\n",
    "#tf_mat = tf.where(tf_mat > 0, tf.ones_like(tf_mat), tf_mat)\n",
    "#zeros = tf.zeros(tf_mat.shape, dtype=tf.dtypes.int32)\n",
    "text_feature = tf.constant([\"test\", \"Test2\"])\n",
    "CLS = tf.fill(tf.shape(text_feature), \"[CLS]\")\n",
    "SEP = tf.fill(tf.shape(text_feature), \"[SEP]\")\n",
    "y = tf.strings.join([CLS, text_feature, SEP], separator=' ')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels, weights=None):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "        \n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            logits=logits, labels=labels, \n",
    "            weights=weights\n",
    "        )\n",
    "        #loss = tf.nn.weighted_cross_entropy_with_logits(labels, logits, pos_weight=weights)\n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    num_labels = params.num_labels\n",
    "    learning_rate = params.learning_rate\n",
    "    num_train_steps = params.num_train_steps\n",
    "    num_warmup_steps = params.num_warmup_steps\n",
    "\n",
    "    input_ids, input_mask, segment_ids  = process_text(features[\"comment_text\"])\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        is_predicting = True\n",
    "        \n",
    "        (predicted_labels, log_probs) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, labels, num_labels)\n",
    "        \n",
    "        predictions = {\n",
    "            'probabilities': log_probs,\n",
    "            'labels': predicted_labels\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          predictions=predictions, \n",
    "                                          export_outputs=export_outputs)\n",
    "    \n",
    "    else:\n",
    "        is_predicting = False\n",
    "        \n",
    "        # weights\n",
    "        weights = features[WEIGHT_COLUNM_NAME]\n",
    "        \n",
    "        (loss, predicted_labels, log_probs) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, labels, num_labels, weights=weights)\n",
    "\n",
    "        train_op = bert.optimization.create_optimizer(\n",
    "            loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "        # Calculate evaluation metrics.\n",
    "        def metric_fn(labels, predicted_labels, log_probs):\n",
    "            accuracy = tf.metrics.accuracy(labels, predicted_labels)\n",
    "            probs = tf.reduce_max(tf.exp(log_probs), axis=-1, keepdims=True)\n",
    "            f1_score = tf.contrib.metrics.f1_score(\n",
    "                labels,\n",
    "                probs)\n",
    "            return {\n",
    "                \"eval_accuracy\": accuracy,\n",
    "                \"f1_score\": f1_score,\n",
    "            }\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              train_op=train_op)\n",
    "        else:\n",
    "            eval_metrics = metric_fn(labels, predicted_labels, log_probs)\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              eval_metric_ops=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "TRAIN_SIZE = 1809000\n",
    "TOTAL_STEPS = int(TRAIN_SIZE / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "WARMUP_STEPS = int(TOTAL_STEPS * WARMUP_PROPORTION)\n",
    "EVAL_AFTER_SEC = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps is 43071. \n",
      "         Total number of warmup steps  is 4307.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Total number of steps is {0}. \n",
    "         Total number of warmup steps  is {1}.\"\"\".format(TOTAL_STEPS, WARMUP_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams  = tf.contrib.training.HParams(\n",
    "    num_epochs = NUM_TRAIN_EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_labels = len(TARGET_LABELS),\n",
    "    num_train_steps = TOTAL_STEPS,\n",
    "    num_warmup_steps = WARMUP_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    model_dir = OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "session_conf.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "session_conf.intra_op_parallelism_threads = multiprocessing.cpu_count()\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    session_config=session_conf,\n",
    "    log_step_count_steps=500,\n",
    "    save_checkpoints_steps=100,\n",
    "    tf_random_seed=17081992,\n",
    "    model_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    \"\"\"\n",
    "    Serving input function, should contain a receiver_tensor with the same features as the input during training, \n",
    "    this function will also be used during validation.\n",
    "    \"\"\"\n",
    "    receiver_tensor = {\n",
    "      'comment_text': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "      key: tensor\n",
    "      for key, tensor in receiver_tensor.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = lambda: input_fn(\n",
    "        TRAIN_DATA_FILES_PATTERN,\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "        num_epochs=NUM_TRAIN_EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    max_steps=hparams.num_train_steps,\n",
    "    hooks=None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = lambda: input_fn(\n",
    "        VALID_DATA_FILES_PATTERN,\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    exporters=[tf.estimator.LatestExporter( #LatestExporter or BestExporter\n",
    "        name=\"predict\", # the name of the folder in which the model will be exported to under export\n",
    "        serving_input_receiver_fn=serving_input_fn,\n",
    "        exports_to_keep=1,\n",
    "        as_text=True)],\n",
    "    steps=None,\n",
    "    throttle_secs = EVAL_AFTER_SEC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './toxic_models/', '_tf_random_seed': 17081992, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 40\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      "log_device_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: ON_1\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd71dcf470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:54.652136 139679930693440 estimator.py:201] Using config: {'_model_dir': './toxic_models/', '_tf_random_seed': 17081992, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 40\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      "log_device_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: ON_1\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd71dcf470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Type: <class 'tensorflow_estimator.python.estimator.estimator.Estimator'>\n"
     ]
    }
   ],
   "source": [
    "def create_estimator(run_config, hparams):\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                  params=hparams,\n",
    "                                  config=run_config)\n",
    "    print(\"Estimator Type: {}\".format(type(estimator)))\n",
    "    return estimator\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started at 14:36:56\n",
      ".......................................\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.850668 139679930693440 estimator_training.py:185] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.855462 139679930693440 training.py:610] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.859523 139679930693440 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/train-*.tsv\n",
      "Batch size: 42\n",
      "Epoch Count: 1\n",
      "Mode: train\n",
      "Thread Count: 40\n",
      "Shuffle: True\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.958705 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:59.161143 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:08.497107 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:08.501667 139679930693440 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:10.198913 139679930693440 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-42976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:10.206092 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-42976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:14.249520 139679930693440 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:14.526021 139679930693440 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 42976 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:21.569036 139679930693440 basic_session_run_hooks.py:594] Saving checkpoints for 42976 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0675094, step = 42976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:48.065519 139679930693440 basic_session_run_hooks.py:249] loss = 0.0675094, step = 42976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 43071 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:14.345851 139679930693440 basic_session_run_hooks.py:594] Saving checkpoints for 43071 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/valid-*.tsv\n",
      "Batch size: 42\n",
      "Epoch Count: 1\n",
      "Mode: eval\n",
      "Thread Count: 40\n",
      "Shuffle: False\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:16.991114 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:20.037435 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:28.100937 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-27T14:39:28Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:28.122597 139679930693440 evaluation.py:257] Starting evaluation at 2019-06-27T14:39:28Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:29.419227 139679930693440 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:29.427072 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:33.134473 139679930693440 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:33.414460 139679930693440 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-27-14:39:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.916481 139679930693440 evaluation.py:277] Finished evaluation at 2019-06-27-14:39:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 43071: eval_accuracy = 0.95844877, f1_score = 0.11991656, global_step = 43071, loss = 0.34091455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.924363 139679930693440 estimator.py:1979] Saving dict for global step 43071: eval_accuracy = 0.95844877, f1_score = 0.11991656, global_step = 43071, loss = 0.34091455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 43071: ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.927732 139679930693440 estimator.py:2039] Saving 'checkpoint_path' summary for global step 43071: ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.943537 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.793039 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.922961 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.935233 139679930693440 export.py:587] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.937599 139679930693440 export.py:587] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.939929 139679930693440 export.py:587] Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.942170 139679930693440 export.py:587] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.945685 139679930693440 export.py:587] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:54.192572 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:55.096708 139679930693440 builder_impl.py:654] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./toxic_models/export/predict/temp-b'1561646389'/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:55.099963 139679930693440 builder_impl.py:763] Assets written to: ./toxic_models/export/predict/temp-b'1561646389'/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./toxic_models/export/predict/temp-b'1561646389'/saved_model.pbtxt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:56.494462 139679930693440 builder_impl.py:414] SavedModel written to: ./toxic_models/export/predict/temp-b'1561646389'/saved_model.pbtxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6736055.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:57.393692 139679930693440 estimator.py:359] Loss for final step: 0.6736055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................\n",
      "Experiment finished at 14:39:57\n",
      "\n",
      "Experiment elapsed time: 180.555674 seconds\n"
     ]
    }
   ],
   "source": [
    "#if not RESUME_TRAINING:\n",
    "#print(\"Removing previous artifacts...\")\n",
    "#shutil.rmtree(OUTPUT_DIR, ignore_errors=True)   \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "time_start = datetime.utcnow() \n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "import logging\n",
    "\n",
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('tensorflow.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec, \n",
    "        eval_spec=eval_spec\n",
    ")\n",
    "\n",
    "time_end = datetime.utcnow() \n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = val_df.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/valid-*.tsv\n",
      "Batch size: 32\n",
      "Epoch Count: 1\n",
      "Mode: eval\n",
      "Thread Count: 40\n",
      "Shuffle: False\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:20.443544 139633935230784 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:22.440176 139633935230784 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:30.104430 139633935230784 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-26T12:06:30Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:30.123854 139633935230784 evaluation.py:257] Starting evaluation at 2019-06-26T12:06:30Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:31.273389 139633935230784 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:31.279703 139633935230784 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:34.059045 139633935230784 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:34.331680 139633935230784 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [372/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:07:46.377252 139633935230784 evaluation.py:169] Evaluation [372/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [744/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:08:56.920406 139633935230784 evaluation.py:169] Evaluation [744/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1116/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:10:07.407554 139633935230784 evaluation.py:169] Evaluation [1116/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1488/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:11:17.899296 139633935230784 evaluation.py:169] Evaluation [1488/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1860/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:12:28.386068 139633935230784 evaluation.py:169] Evaluation [1860/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2232/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:13:38.859268 139633935230784 evaluation.py:169] Evaluation [2232/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2604/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:14:49.320812 139633935230784 evaluation.py:169] Evaluation [2604/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2976/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:15:59.776804 139633935230784 evaluation.py:169] Evaluation [2976/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3348/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:17:10.231661 139633935230784 evaluation.py:169] Evaluation [3348/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3720/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:20.713017 139633935230784 evaluation.py:169] Evaluation [3720/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3722/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.098714 139633935230784 evaluation.py:169] Evaluation [3722/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-26-12:18:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.491169 139633935230784 evaluation.py:277] Finished evaluation at 2019-06-26-12:18:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100000: eval_accuracy = 0.9622095, f1_score = 0.112007596, global_step = 100000, loss = 0.42697436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.494870 139633935230784 estimator.py:1979] Saving dict for global step 100000: eval_accuracy = 0.9622095, f1_score = 0.112007596, global_step = 100000, loss = 0.42697436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100000: ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.499738 139633935230784 estimator.py:2039] Saving 'checkpoint_path' summary for global step 100000: ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Measures: {'eval_accuracy': 0.9622095, 'f1_score': 0.112007596, 'loss': 0.42697436, 'global_step': 100000}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = lambda: input_fn(files_name_pattern= VALID_DATA_FILES_PATTERN, \n",
    "                                      mode= tf.estimator.ModeKeys.EVAL,\n",
    "                                      batch_size= BATCH_SIZE)\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn, steps=steps)\n",
    "print(\"# Test Measures: {}\".format(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./toxic_models/export/predict/1561646389 \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./toxic_models/export/predict/1561646389/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:45:48.735315 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/export/predict/1561646389/variables/variables\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "export_dir = \"./toxic_models/export/predict\"\n",
    "\n",
    "saved_model_dir = export_dir + \"/\" + os.listdir(path=export_dir)[-1] \n",
    "\n",
    "print(saved_model_dir, \"\\n\")\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = saved_model_dir,\n",
    "    signature_def_key=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cdebfc349d4329913919b30bb58fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1805, style=ProgressStyle(description_widtâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_result = val_df['comment_text'].swifter.apply(lambda text: predictor_fn({'comment_text': [text]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cd5232278d49408f1fd069d6253fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_widâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_result = test_df['comment_text'].swifter.apply(lambda text: predictor_fn({'comment_text': [text]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([x['labels'] for x in val_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK] , please , please , could this des ##pic ##able sh ##rew just get lost in the woods and stay there .',\n",
       " '[UNK] to mention having the first openly gay player in [UNK] history : [UNK] [UNK] . . .',\n",
       " '\" [UNK] racism over brown people \" ? [UNK] 3d , now that is not [UNK] !',\n",
       " \"[UNK] respectful ##ly disagree ; it [UNK] a complex problem . [UNK] ' s why racism and big ##ot ##ry are as old as humanity itself . [UNK] , [UNK] do agree [UNK] cannot solve it ; he is incapable of solving any problems . [UNK] only make problems . [UNK] this case , it is [UNK] who has em ##bold ##ened the far right big ##ots and lifted the rock under which white su ##pre ##mac ##ists live . [UNK] ' re out and loud and are benefit ##ing from [UNK] ' s app ##all ##ing statements indicating a moral e ##qui ##vale ##ncy between white supremacy and social justice protests . [UNK] ' s absolutely disgusting that the [UNK] president behave ##s this way .\",\n",
       " '[UNK] do not sp ##ew a silly insult , [UNK] [UNK] [UNK] . [UNK] up all the evidence and make him eat his words .',\n",
       " '[UNK] all [UNK] are [UNK] . [UNK] in any form is evil .',\n",
       " '\" [UNK] \" ? [UNK] . [UNK] are more colors in my immediate family than in your entire voting district . [UNK] darkest - complexion ##ed among my family - - those of [UNK] , [UNK] , [UNK] and [UNK] descent - - would be most outraged to hear their peoples \\' struggles trivial ##ized by being compared to pathetic , bourgeois \" id ##eo ##logue ##s \" shriek ##ing and fl ##ailing about how their sexual practices should en ##ti ##tle them to special recognition .',\n",
       " 'the shoe would also fit using terms like \" dedicated \" \" strong believer \" . . do you like being called a trump vo ##tin w ##ha ##cko ? and still no source for the injuries - \" fake ##y news ##y \" on your part some might say - bull sh * t says [UNK]',\n",
       " '[UNK] ! \" [UNK] least [UNK] speaks the truth \" is the fun ##nies ##t thing [UNK] have ever heard by anyone describing a well - known , confirmed path ##ological liar . [UNK] is a potent drug . [UNK] people are addict ##s .',\n",
       " '[UNK] [UNK] women [UNK] [UNK] [UNK] [UNK] .',\n",
       " 'app whatever writes : \" [UNK] \\' t give us that crap about out of town ##ers coming here and dropping bucket ##s of money either . [UNK] does not happen . \" - [UNK] does . [UNK] do you think fills the restaurants every day , stays in the city for dinner and shops there ? [UNK] the retailers and restaurant owners if they think it is a good idea to discourage people from driving into [UNK] . [UNK] statement made out of ignorance .',\n",
       " '[UNK] camped in proximity to bear bait ##s myself for decades now without having any such problems , [UNK] would say [UNK] . [UNK] needs a dose of reality to go along with his ridiculous theory !',\n",
       " '[UNK] father had a saying : [UNK] in one hand and s * * t in the other and see which one gets full fastest .',\n",
       " '[UNK] , you are just repeating talking points , find the truth , [UNK] predict a huge swing away from the dem . party with the inner city voters , all citizens . [UNK] are getting fed up with being used and taken for granted , although there are still those who refuse to open their minds and look at results , preferring to just fall lock step in with hollow words spoken from their party leaders . http : / / www . ny ##time ##s . com / 2016 / 09 / 05 / us / politics / young - blacks - voice - skepticism - on - hillary - clinton - worrying - democrats . html ? _ r = 0 â€œ [UNK] am [UNK] supposed to do if [UNK] do not like him and [UNK] do not trust her ? â€ a millennia ##l black woman in [UNK] asked . â€œ [UNK] between being stabbed and being shot ? [UNK] way ! â€ â€œ [UNK] was part of the whole problem that started sending blacks to jail , â€ a young black man , also from [UNK] , observed about [UNK] . [UNK] . â€œ [UNK] â€™ s a racist , and she is a liar , so really what is the difference in choosing both or choosing neither ? â€ another young black woman from [UNK] said .',\n",
       " \"[UNK] secret to negotiating with the [UNK] is to ignore the orange dump ##ster entirely , and get on with talks with the people that matter . [UNK] ' s like one of those in ##fl ##atable tubular clown ##s that you see on the roofs of car dealers ##hips : he waves back and forth and flaps his arms mania ##cal ##ly , but actually does precisely nothing .\",\n",
       " '[UNK] [UNK] was ridiculous yesterday of course , but [UNK] also enjoy seeing [UNK] progress and get better . [UNK] game . [UNK] [UNK] ! ! !',\n",
       " '[UNK] . [UNK] will not visit the [UNK] [UNK] of [UNK] because of all the angry white guys with guns .',\n",
       " \"[UNK] protesters supporting white nationalism - creepy . [UNK] who think en ##sl ##avi ##ng other humans is acceptable - creepy . [UNK] who think they are superior to women - creepy . [UNK] things those white men at the park support should be publicly denounced , and they should be humiliated . [UNK] is unacceptable and we need to fr ##ig ##gin ' say so , loudly .\",\n",
       " '[UNK] me get this straight . [UNK] \\' s lying h ##yp ##oc ##ris ##y is abs ##olved or somehow justified by [UNK] \\' s lies ? [UNK] ? [UNK] for the classic example of \" what ##ab ##out ##ism . \"',\n",
       " '[UNK] is described as \" bat s * * t insane \" blog favored by conspiracy theorists . [UNK] is published under pseudonym ##s so no one knows who actually writes it . [UNK] perfect for you , [UNK] .',\n",
       " '[UNK] in the shoes of a black man and perhaps you will understand .',\n",
       " \"[UNK] ' s some pretty fast bullet forensic ##s conducted [UNK] . [UNK] hope you are right about this guy . [UNK] wondered if there was a serial killer amongst us and based on this early report , this guy may have been a serial killer living amongst us . [UNK] damn scary is that ?\",\n",
       " '[UNK] hope they plan to pay the carbon tax , otherwise everything you have written is just white wash . [UNK] of course , how silly of me , they will be exempt .',\n",
       " \"bu ##rka sc ##hm ##ur ##ka ##how about a ban on muslim men pinch ##ing ladies ' bottoms in public places\",\n",
       " 'lobbying for the health [UNK] [UNK] [UNK] ? . [UNK] are these people ? [UNK] would even do that ? you are the bane of democracy . [UNK] hope my elected officials read this and know that we are not totally ignorant . 50 people need to go to jail .',\n",
       " '[UNK] dirty tag - team hit .',\n",
       " '[UNK] party harbor ##s the white su ##pre ##mist ##s and big ##ots , and some other fine people . . . . . . . . . . bon ##g , bon ##g , bon ##g , lo ##l',\n",
       " '[UNK] [UNK] said in a personal email to sheriff [UNK] , if he keeps his oath of office to defend the [UNK] against [UNK] enemies , foreign [UNK] [UNK] , and stands firm in the authority of his office and his commitment to protecting the rights of his [UNK] , the \" patriots \" will be at his command whether he says stay out or come help me . [UNK] , if he fails to keep his oath be it intentional or out of ignorance , the people will be [UNK] [UNK] [UNK] to continue listening to him . [UNK] - [UNK] [UNK] [UNK] [UNK] [UNK] on the [UNK] and [UNK] \" [UNK] \" , and stop ##making ignorant statements that make you sound like an idiot and a sub ##ser ##vie ##nt boot licking slave of an ##op ##pressive , out of control federal corporation , est . in 1871 and calling itself \" [UNK] [UNK] [UNK] \" ( see [UNK] [UNK] , [UNK] 28 , 300 ##2 , 15 ( a ) and look up this corporation on [UNK] and [UNK] , and also seen ##ot 1 but 2 [UNK] [UNK] [UNK] cases that acknowledge this non - constitutional national corporate government .',\n",
       " '[UNK] ah ##ah ##hh ##ha ##aa ##ah ##ha ##aa ##ah ##ha ##a [UNK] fool only yourself with lies like that .',\n",
       " '[UNK] [UNK] writes : \" [UNK] [UNK] imp ##ea ##chment \\' fantasy is all over \" - [UNK] [UNK] do not actually want [UNK] imp ##ea ##ched . [UNK] want him to run again in 2020 . [UNK] duck . [UNK] he is imp ##ea ##ched then the [UNK] can run someone else in 2020 . [UNK] [UNK] are dar ##ned if they do , dar ##ned if they do not .',\n",
       " '[UNK] do not hate my leftist non friend . [UNK] i do not shoot , kill , stab , or wound . . . . in the name of [UNK] , [UNK] , [UNK] , [UNK] or any other man made deity . [UNK] words might hurt , but the truth sometimes does . [UNK] back to sucking on the public tee ##t [UNK] , it is at least something you are good at .',\n",
       " \"h ##yp ##oc ##ris ##y ? [UNK] ' s why he got arrested . . . no more , and no less than any one else .\",\n",
       " '[UNK] hope she immediately reported this threat to the authorities . [UNK] a kn ##uck ##le - dragging cr ##eti ##n of a man .',\n",
       " '\" [UNK] do not take me alive , crooked [UNK] [UNK] copper ! \"',\n",
       " '[UNK] , like [UNK] , are betting getting their names in the paper by spreading hatred . [UNK] sound like a real estate con ##man / \" reality \" [UNK] game show host turned politician .',\n",
       " '[UNK] is a great move by [UNK] considering the recent \" free speech \" cancellation by [UNK] [UNK] after they decided conservative speakers are not en ##ti ##tle to the first amendment . [UNK] , students are too stupid to understand conservative viewpoint ##s are counter - productive to the utopia ##n , socialist society academics dream about . . . because the [UNK] , [UNK] & [UNK] all went about it the wrong way , right ?',\n",
       " '[UNK] [UNK] should remember that there is a dead [UNK] for every mile of railway across [UNK] ! ! ! [UNK] stop writing garbage about our relationship . [UNK] is naive except [UNK] .',\n",
       " '[UNK] is literally blackmail ##ing the [UNK] [UNK] . [UNK] : if you give [UNK] full pardon ; then [UNK] will give you the secret info he gave me . [UNK] is a traitor against [UNK] & he has been a traitor for [UNK]',\n",
       " '[UNK] ! [UNK] just pa ##ve the whole fr ##ig ##gin town . [UNK] while they are at it , they can clear - cut all the parks around town and fill them up with site condo ##s . [UNK] , and pa ##ve over the [UNK] [UNK] . . . just think of all the parking ! ! ! !',\n",
       " '[UNK] , you could have stopped at \" [UNK] cannot think \" and had a statement that ##s 100 % accurate . [UNK] you put in a bunch of trash that proves you \" can not think \" .',\n",
       " '[UNK] [UNK] are far and way the most aggressive avoid ##ers of tax in the land . [UNK] one is dumb enough to put it in print as such shows how bra ##zen they have become . [UNK] in this country is at an all time low .',\n",
       " '[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] . . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] ! !',\n",
       " '[UNK] terror attacks you mean like [UNK] ? ? ? [UNK] are [UNK] [UNK] [UNK] , [UNK] said those are [UNK] , nothing to worry about there . . . # [UNK]',\n",
       " '[UNK] the h * * * is he ? [UNK] un ##qual ##ified family member .',\n",
       " '[UNK] said it ! [UNK] for you ! [UNK] are bull ##ies .',\n",
       " '[UNK] me with a spoon . [UNK] [UNK] it is politics all right , you are giving ta ##cit support to [UNK] [UNK] and his insulting policies . [UNK] a [UNK] , [UNK] find these corporate , shallow [UNK] pro hockey players being fe ##ted by [UNK] naive , pathetic , and an embarrassment . [UNK] different than the attitude of spectators who attended the 1936 [UNK] [UNK] .',\n",
       " '[UNK] did hear what he said and [UNK] do not agree with all of it . [UNK] disagree with his stance on global warming , bringing coal back , making [UNK] pay for the wall and right now [UNK] am not impressed with his [UNK] head pick . [UNK] , those issues are not why [UNK] voted for him . [UNK] voted for him due to his other views such as thinking of the [UNK] [UNK] first , rebuilding our crumbling infrastructure , protecting our border , his \" anti - global ##ism \" stance , stopping the fleeing corporations from leaving the [UNK] . [UNK] . and other things . [UNK] was more factual ##ly correct , but pretty much everything she said was not her own thought . [UNK] came off as a robot , a dec ##eptive liar and she via the [UNK] [UNK] are incredibly corrupt . [UNK] plan to keep red ##ist ##ri ##bu ##ting wealth to gain votes is a bunch of crap also ( look at her tax plan ) . [UNK] [UNK] supporters took / take [UNK] literally , but not seriously . [UNK] supporters take him seriously , but not literally . [UNK] wild ride is going to begin .',\n",
       " '[UNK] what are they showing courage against . [UNK] are they not showing courage for all the veterans who have over the years died for their country and the ideals that have kept this country strong . [UNK] is obviously not the first idiot president that we have had ( and he most surely will not be the last ) , but you players not respecting the flag & the anthem , let alone the veterans that fought and died for you to be absolute babies makes me very sad even admit [UNK] watch the [UNK]',\n",
       " '[UNK] can see why . [UNK] are not dumb ; they can see what [UNK] thinks of [UNK] [UNK] .',\n",
       " '[UNK] a writer trying to get some attention - anyone that looks at this is a score for [UNK] [UNK] who is trying to make his way in the new dar ##n world of journalism . [UNK] a rookie .',\n",
       " '[UNK] is a med ##io ##cre talent who turned her back on [UNK] when she left for [UNK] . [UNK] stood up the [UNK] [UNK] [UNK] and thanks to [UNK] [UNK] the show went on . [UNK] was caught lip sync ##ing the national anthem on [UNK] . [UNK] it benefits her to be an \" [UNK] woman \" . [UNK] the bar ##f bag . [UNK] thanks to a real talent : [UNK] [UNK] .',\n",
       " '[UNK] again . . . . [UNK] [UNK] [UNK] [UNK] [UNK] known as [UNK] continues to bring terror to the world . [UNK] of [UNK] and [UNK] - right ? ? [UNK] up [UNK] ! !',\n",
       " \"[UNK] matter how you slice it people are just crap full of hatred . [UNK] ' s always been this way and the internet just amp ##li ##fies this .\"]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[(~(val_df.target.values == predictions)) & (val_df.target == 0)].comment_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array([x['probabilities'][0][1] for x in test_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'] = np.exp(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"./bert_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7097320</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7097321</td>\n",
       "      <td>0.102077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7097322</td>\n",
       "      <td>0.022385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7097323</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7097324</td>\n",
       "      <td>0.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7097325</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7097326</td>\n",
       "      <td>0.082860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7097327</td>\n",
       "      <td>0.192811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7097328</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7097329</td>\n",
       "      <td>0.001392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7097330</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7097331</td>\n",
       "      <td>0.167843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7097332</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7097333</td>\n",
       "      <td>0.002051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7097334</td>\n",
       "      <td>0.036402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7097335</td>\n",
       "      <td>0.132002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7097336</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7097337</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7097338</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7097339</td>\n",
       "      <td>0.900396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7097340</td>\n",
       "      <td>0.012515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7097341</td>\n",
       "      <td>0.019033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7097342</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7097343</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7097344</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7097345</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7097346</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7097347</td>\n",
       "      <td>0.014317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7097348</td>\n",
       "      <td>0.010767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7097349</td>\n",
       "      <td>0.011533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97290</th>\n",
       "      <td>7194610</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97291</th>\n",
       "      <td>7194611</td>\n",
       "      <td>0.033361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97292</th>\n",
       "      <td>7194612</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97293</th>\n",
       "      <td>7194613</td>\n",
       "      <td>0.005443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97294</th>\n",
       "      <td>7194614</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97295</th>\n",
       "      <td>7194615</td>\n",
       "      <td>0.021078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97296</th>\n",
       "      <td>7194616</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97297</th>\n",
       "      <td>7194617</td>\n",
       "      <td>0.013326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>7194618</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97299</th>\n",
       "      <td>7194619</td>\n",
       "      <td>0.026829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97300</th>\n",
       "      <td>7194620</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97301</th>\n",
       "      <td>7194621</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97302</th>\n",
       "      <td>7194622</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>7194623</td>\n",
       "      <td>0.004665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>7194624</td>\n",
       "      <td>0.999275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97305</th>\n",
       "      <td>7194625</td>\n",
       "      <td>0.999257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>7194626</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97307</th>\n",
       "      <td>7194627</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97308</th>\n",
       "      <td>7194628</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97309</th>\n",
       "      <td>7194629</td>\n",
       "      <td>0.009236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>7194630</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97311</th>\n",
       "      <td>7194631</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97312</th>\n",
       "      <td>7194632</td>\n",
       "      <td>0.005855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97313</th>\n",
       "      <td>7194633</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97314</th>\n",
       "      <td>7194634</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97315</th>\n",
       "      <td>7194635</td>\n",
       "      <td>0.012279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97316</th>\n",
       "      <td>7194636</td>\n",
       "      <td>0.002902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97317</th>\n",
       "      <td>7194637</td>\n",
       "      <td>0.962759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97318</th>\n",
       "      <td>7194638</td>\n",
       "      <td>0.109350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97319</th>\n",
       "      <td>7194639</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prediction\n",
       "0      7097320    0.002762\n",
       "1      7097321    0.102077\n",
       "2      7097322    0.022385\n",
       "3      7097323    0.006065\n",
       "4      7097324    0.001761\n",
       "5      7097325    0.000715\n",
       "6      7097326    0.082860\n",
       "7      7097327    0.192811\n",
       "8      7097328    0.003471\n",
       "9      7097329    0.001392\n",
       "10     7097330    0.003144\n",
       "11     7097331    0.167843\n",
       "12     7097332    0.006723\n",
       "13     7097333    0.002051\n",
       "14     7097334    0.036402\n",
       "15     7097335    0.132002\n",
       "16     7097336    0.006351\n",
       "17     7097337    0.000898\n",
       "18     7097338    0.000929\n",
       "19     7097339    0.900396\n",
       "20     7097340    0.012515\n",
       "21     7097341    0.019033\n",
       "22     7097342    0.001089\n",
       "23     7097343    0.000736\n",
       "24     7097344    0.002833\n",
       "25     7097345    0.002747\n",
       "26     7097346    0.007376\n",
       "27     7097347    0.014317\n",
       "28     7097348    0.010767\n",
       "29     7097349    0.011533\n",
       "...        ...         ...\n",
       "97290  7194610    0.000754\n",
       "97291  7194611    0.033361\n",
       "97292  7194612    0.004975\n",
       "97293  7194613    0.005443\n",
       "97294  7194614    0.003040\n",
       "97295  7194615    0.021078\n",
       "97296  7194616    0.006351\n",
       "97297  7194617    0.013326\n",
       "97298  7194618    0.002088\n",
       "97299  7194619    0.026829\n",
       "97300  7194620    0.002951\n",
       "97301  7194621    0.002418\n",
       "97302  7194622    0.000858\n",
       "97303  7194623    0.004665\n",
       "97304  7194624    0.999275\n",
       "97305  7194625    0.999257\n",
       "97306  7194626    0.004789\n",
       "97307  7194627    0.001318\n",
       "97308  7194628    0.004658\n",
       "97309  7194629    0.009236\n",
       "97310  7194630    0.000730\n",
       "97311  7194631    0.001134\n",
       "97312  7194632    0.005855\n",
       "97313  7194633    0.003142\n",
       "97314  7194634    0.000918\n",
       "97315  7194635    0.012279\n",
       "97316  7194636    0.002902\n",
       "97317  7194637    0.962759\n",
       "97318  7194638    0.109350\n",
       "97319  7194639    0.000819\n",
       "\n",
       "[97320 rows x 2 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
