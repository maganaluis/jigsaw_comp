{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from tensorflow import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6194197965567352402, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14742444489581862372\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 907751022919386053\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 32039642727\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8611099686685878167\n",
       " physical_device_desc: \"device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\"]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import multiprocessing\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'toxic_model'\n",
    "TRAIN_DATA_FILES_PATTERN = 'data/processed/train-*.tsv'\n",
    "VALID_DATA_FILES_PATTERN = 'data/processed/valid-*.tsv'\n",
    "RESUME_TRAINING = True\n",
    "MULTI_THREADING = True\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "CLASS_TO_LABEL = {'toxic': 0, 'non-toxic': 1}\n",
    "BERT_PRETRAINED_DIR = '/home/luis.magana/BERT/uncased_L-12_H-768_A-12/'\n",
    "TARGET_LABELS = ['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 42\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Set the output directory for saving model file\n",
    "# Optionally, set a GCP bucket location\n",
    "OUTPUT_DIR = './toxic_models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 220\n",
    "PAD_WORD = '#=KS=#'\n",
    "HEADER_DEFAULTS = [['NA'], ['NA'], ['NA']]\n",
    "TARGET_NAME = 'target'\n",
    "WEIGHT_COLUNM_NAME = 'weight' #This will not be used for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('https://s3.amazonaws.com/ccwf-ml-data/jigsaw/test.csv')\n",
    "train_df = pd.read_csv('https://s3.amazonaws.com/ccwf-ml-data/jigsaw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "train_df['target'] = train_df['target'].apply(lambda x: 0 if x <= 0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_to_isolate = '.,?!-;*\"…:—()%#$&_/@＼・ω+=”“[]^–>\\\\°<~•≠™ˈʊɒ∞§{}·τα❤☺ɡ|¢→̶`❥━┣┫┗Ｏ►★©―ɪ✔®\\x96\\x92●£♥➤´¹☕≈÷♡◐║▬′ɔː€۩۞†μ✒➥═☆ˌ◄½ʻπδηλσερνʃ✬ＳＵＰＥＲＩＴ☻±♍µº¾✓◾؟．⬅℅»Вав❣⋅¿¬♫ＣＭβ█▓▒░⇒⭐›¡₂₃❧▰▔◞▀▂▃▄▅▆▇↙γ̄″☹➡«φ⅓„✋：¥̲̅́∙‛◇✏▷❓❗¶˚˙）сиʿ✨。ɑ\\x80◕！％¯−ﬂﬁ₁²ʌ¼⁴⁄₄⌠♭✘╪▶☭✭♪☔☠♂☃☎✈✌✰❆☙○‣⚓年∎ℒ▪▙☏⅛ｃａｓǀ℮¸ｗ‚∼‖ℳ❄←☼⋆ʒ⊂、⅔¨͡๏⚾⚽Φ×θ￦？（℃⏩☮⚠月✊❌⭕▸■⇌☐☑⚡☄ǫ╭∩╮，例＞ʕɐ̣Δ₀✞┈╱╲▏▕┃╰▊▋╯┳┊≥☒↑☝ɹ✅☛♩☞ＡＪＢ◔◡↓♀⬆̱ℏ\\x91⠀ˤ╚↺⇤∏✾◦♬³の｜／∵∴√Ω¤☜▲↳▫‿⬇✧ｏｖｍ－２０８＇‰≤∕ˆ⚜☁'\n",
    "symbols_to_delete = '\\n🍕\\r🐵😑\\xa0\\ue014\\t\\uf818\\uf04a\\xad😢🐶️\\uf0e0😜😎👊\\u200b\\u200e😁عدويهصقأناخلىبمغر😍💖💵Е👎😀😂\\u202a\\u202c🔥😄🏻💥ᴍʏʀᴇɴᴅᴏᴀᴋʜᴜʟᴛᴄᴘʙғᴊᴡɢ😋👏שלוםבי😱‼\\x81エンジ故障\\u2009🚌ᴵ͞🌟😊😳😧🙀😐😕\\u200f👍😮😃😘אעכח💩💯⛽🚄🏼ஜ😖ᴠ🚲‐😟😈💪🙏🎯🌹😇💔😡\\x7f👌ἐὶήιὲκἀίῃἴξ🙄Ｈ😠\\ufeff\\u2028😉😤⛺🙂\\u3000تحكسة👮💙فزط😏🍾🎉😞\\u2008🏾😅😭👻😥😔😓🏽🎆🍻🍽🎶🌺🤔😪\\x08‑🐰🐇🐱🙆😨🙃💕𝘊𝘦𝘳𝘢𝘵𝘰𝘤𝘺𝘴𝘪𝘧𝘮𝘣💗💚地獄谷улкнПоАН🐾🐕😆ה🔗🚽歌舞伎🙈😴🏿🤗🇺🇸мυтѕ⤵🏆🎃😩\\u200a🌠🐟💫💰💎эпрд\\x95🖐🙅⛲🍰🤐👆🙌\\u2002💛🙁👀🙊🙉\\u2004ˢᵒʳʸᴼᴷᴺʷᵗʰᵉᵘ\\x13🚬🤓\\ue602😵άοόςέὸתמדףנרךצט😒͝🆕👅👥👄🔄🔤👉👤👶👲🔛🎓\\uf0b7\\uf04c\\x9f\\x10成都😣⏺😌🤑🌏😯ех😲Ἰᾶὁ💞🚓🔔📚🏀👐\\u202d💤🍇\\ue613小土豆🏡❔⁉\\u202f👠》कर्मा🇹🇼🌸蔡英文🌞🎲レクサス😛外国人关系Сб💋💀🎄💜🤢َِьыгя不是\\x9c\\x9d🗑\\u2005💃📣👿༼つ༽😰ḷЗз▱ц￼🤣卖温哥华议会下降你失去所有的钱加拿大坏税骗子🐝ツ🎅\\x85🍺آإشء🎵🌎͟ἔ油别克🤡🤥😬🤧й\\u2003🚀🤴ʲшчИОРФДЯМюж😝🖑ὐύύ特殊作戦群щ💨圆明园קℐ🏈😺🌍⏏ệ🍔🐮🍁🍆🍑🌮🌯🤦\\u200d𝓒𝓲𝓿𝓵안영하세요ЖљКћ🍀😫🤤ῦ我出生在了可以说普通话汉语好极🎼🕺🍸🥂🗽🎇🎊🆘🤠👩🖒🚪天一家⚲\\u2006⚭⚆⬭⬯⏖新✀╌🇫🇷🇩🇪🇮🇬🇧😷🇨🇦ХШ🌐\\x1f杀鸡给猴看ʁ𝗪𝗵𝗲𝗻𝘆𝗼𝘂𝗿𝗮𝗹𝗶𝘇𝗯𝘁𝗰𝘀𝘅𝗽𝘄𝗱📺ϖ\\u2000үսᴦᎥһͺ\\u2007հ\\u2001ɩｙｅ൦ｌƽｈ𝐓𝐡𝐞𝐫𝐮𝐝𝐚𝐃𝐜𝐩𝐭𝐢𝐨𝐧Ƅᴨןᑯ໐ΤᏧ௦Іᴑ܁𝐬𝐰𝐲𝐛𝐦𝐯𝐑𝐙𝐣𝐇𝐂𝐘𝟎ԜТᗞ౦〔Ꭻ𝐳𝐔𝐱𝟔𝟓𝐅🐋ﬃ💘💓ё𝘥𝘯𝘶💐🌋🌄🌅𝙬𝙖𝙨𝙤𝙣𝙡𝙮𝙘𝙠𝙚𝙙𝙜𝙧𝙥𝙩𝙪𝙗𝙞𝙝𝙛👺🐷ℋ𝐀𝐥𝐪🚶𝙢Ἱ🤘ͦ💸ج패티Ｗ𝙇ᵻ👂👃ɜ🎫\\uf0a7БУі🚢🚂ગુજરાતીῆ🏃𝓬𝓻𝓴𝓮𝓽𝓼☘﴾̯﴿₽\\ue807𝑻𝒆𝒍𝒕𝒉𝒓𝒖𝒂𝒏𝒅𝒔𝒎𝒗𝒊👽😙\\u200cЛ‒🎾👹⎌🏒⛸公寓养宠物吗🏄🐀🚑🤷操美𝒑𝒚𝒐𝑴🤙🐒欢迎来到阿拉斯ספ𝙫🐈𝒌𝙊𝙭𝙆𝙋𝙍𝘼𝙅ﷻ🦄巨收赢得白鬼愤怒要买额ẽ🚗🐳𝟏𝐟𝟖𝟑𝟕𝒄𝟗𝐠𝙄𝙃👇锟斤拷𝗢𝟳𝟱𝟬⦁マルハニチロ株式社⛷한국어ㄸㅓ니͜ʖ𝘿𝙔₵𝒩ℯ𝒾𝓁𝒶𝓉𝓇𝓊𝓃𝓈𝓅ℴ𝒻𝒽𝓀𝓌𝒸𝓎𝙏ζ𝙟𝘃𝗺𝟮𝟭𝟯𝟲👋🦊多伦🐽🎻🎹⛓🏹🍷🦆为和中友谊祝贺与其想象对法如直接问用自己猜本传教士没积唯认识基督徒曾经让相信耶稣复活死怪他但当们聊些政治题时候战胜因圣把全堂结婚孩恐惧且栗谓这样还♾🎸🤕🤒⛑🎁批判检讨🏝🦁🙋😶쥐스탱트뤼도석유가격인상이경제황을렵게만들지않록잘관리해야합다캐나에서대마초와화약금의품런성분갈때는반드시허된사용🔫👁凸ὰ💲🗯𝙈Ἄ𝒇𝒈𝒘𝒃𝑬𝑶𝕾𝖙𝖗𝖆𝖎𝖌𝖍𝖕𝖊𝖔𝖑𝖉𝖓𝖐𝖜𝖞𝖚𝖇𝕿𝖘𝖄𝖛𝖒𝖋𝖂𝕴𝖟𝖈𝕸👑🚿💡知彼百\\uf005𝙀𝒛𝑲𝑳𝑾𝒋𝟒😦𝙒𝘾𝘽🏐𝘩𝘨ὼṑ𝑱𝑹𝑫𝑵𝑪🇰🇵👾ᓇᒧᔭᐃᐧᐦᑳᐨᓃᓂᑲᐸᑭᑎᓀᐣ🐄🎈🔨🐎🤞🐸💟🎰🌝🛳点击查版🍭𝑥𝑦𝑧ＮＧ👣\\uf020っ🏉ф💭🎥Ξ🐴👨🤳🦍\\x0b🍩𝑯𝒒😗𝟐🏂👳🍗🕉🐲چی𝑮𝗕𝗴🍒ꜥⲣⲏ🐑⏰鉄リ事件ї💊「」\\uf203\\uf09a\\uf222\\ue608\\uf202\\uf099\\uf469\\ue607\\uf410\\ue600燻製シ虚偽屁理屈Г𝑩𝑰𝒀𝑺🌤𝗳𝗜𝗙𝗦𝗧🍊ὺἈἡχῖΛ⤏🇳𝒙ψՁմեռայինրւդձ冬至ὀ𝒁🔹🤚🍎𝑷🐂💅𝘬𝘱𝘸𝘷𝘐𝘭𝘓𝘖𝘹𝘲𝘫کΒώ💢ΜΟΝΑΕ🇱♲𝝈↴💒⊘Ȼ🚴🖕🖤🥘📍👈➕🚫🎨🌑🐻𝐎𝐍𝐊𝑭🤖🎎😼🕷ｇｒｎｔｉｄｕｆｂｋ𝟰🇴🇭🇻🇲𝗞𝗭𝗘𝗤👼📉🍟🍦🌈🔭《🐊🐍\\uf10aლڡ🐦\\U0001f92f\\U0001f92a🐡💳ἱ🙇𝗸𝗟𝗠𝗷🥜さようなら🔼'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions #pip install contractions\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions.contractions_dict.keys()))\n",
    "def expand_contractions(s, contractions_dict=contractions.contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\n",
    "remove_dict = {ord(c):f'' for c in symbols_to_delete}\n",
    "\n",
    "\n",
    "def handle_punctuation(x):\n",
    "    x = x.translate(remove_dict)\n",
    "    x = x.translate(isolate_dict)\n",
    "    return x\n",
    "\n",
    "def handle_contractions(x):\n",
    "    x = expand_contractions(x)\n",
    "    return x.split(' ')\n",
    "\n",
    "def fix_quote(x):\n",
    "    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n",
    "    x = ' '.join(x)\n",
    "    return x\n",
    "\n",
    "def preprocess(x):\n",
    "    x = handle_punctuation(x)\n",
    "    x = handle_contractions(x)\n",
    "    x = fix_quote(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4656fd441e4b4857ab3c1fc42557f4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=160, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].swifter.allow_dask_on_strings(enable=True).apply(lambda x:preprocess(x))\n",
    "test_df['comment_text'] = test_df['comment_text'].swifter.allow_dask_on_strings(enable=True).apply(lambda x:preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805, 45)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410170</th>\n",
       "      <td>5842313</td>\n",
       "      <td>0</td>\n",
       "      <td>To Daniel Sage of Centennial  -  the KKK did n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370650</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803472</th>\n",
       "      <td>5103997</td>\n",
       "      <td>0</td>\n",
       "      <td>Another day ,  another WWIII advocacy piece fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>325163</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197005</th>\n",
       "      <td>5578826</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Dare \"  needs to be resigned as a non worki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>354489</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                                       comment_text  \\\n",
       "1410170  5842313       0  To Daniel Sage of Centennial  -  the KKK did n...   \n",
       "803472   5103997       0  Another day ,  another WWIII advocacy piece fr...   \n",
       "1197005  5578826       0   \" Dare \"  needs to be resigned as a non worki...   \n",
       "\n",
       "         severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "1410170              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "803472               0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "1197005              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1410170      0.0  ...      370650  approved      0    0    0      1         0   \n",
       "803472       0.0  ...      325163  rejected      0    0    0      7         0   \n",
       "1197005      0.0  ...      354489  approved      0    0    0      1         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1410170              0.0                         0                         4  \n",
       "803472               0.0                         0                         4  \n",
       "1197005              0.0                         0                         4  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.941032\n",
       "1    0.058968\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1410170</th>\n",
       "      <td>5842313</td>\n",
       "      <td>0</td>\n",
       "      <td>To Daniel Sage of Centennial  -  the KKK did n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>370650</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803472</th>\n",
       "      <td>5103997</td>\n",
       "      <td>0</td>\n",
       "      <td>Another day ,  another WWIII advocacy piece fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>325163</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197005</th>\n",
       "      <td>5578826</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Dare \"  needs to be resigned as a non worki...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>354489</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  target                                       comment_text  \\\n",
       "1410170  5842313       0  To Daniel Sage of Centennial  -  the KKK did n...   \n",
       "803472   5103997       0  Another day ,  another WWIII advocacy piece fr...   \n",
       "1197005  5578826       0   \" Dare \"  needs to be resigned as a non worki...   \n",
       "\n",
       "         severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "1410170              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "803472               0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "1197005              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "\n",
       "         atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "1410170      0.0  ...      370650  approved      0    0    0      1         0   \n",
       "803472       0.0  ...      325163  rejected      0    0    0      7         0   \n",
       "1197005      0.0  ...      354489  approved      0    0    0      1         0   \n",
       "\n",
       "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "1410170              0.0                         0                         4  \n",
       "803472               0.0                         0                         4  \n",
       "1197005              0.0                         0                         4  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = [\"id\", \"target\", \"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import tokenization\n",
    "import os\n",
    "\n",
    "\n",
    "VOCAB_LIST_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_LIST_FILE, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5fbee29e7140b29329f9f075c1e567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=160, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_df['comment_text'] = train_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n",
    "test_df['comment_text'] = test_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa9204a33b74c5c83788e1c3c860a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Dask Apply', max=158, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_df['comment_text'] = val_df['comment_text'].swifter.allow_dask_on_strings().apply(lambda x: ' '.join(tokenizer.tokenize(str(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.988081\n",
       "1    0.011919\n",
       "Name: comment_text, dtype: float64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = test_df['comment_text'].apply(lambda x: len(x.split(' ')))\n",
    "s.plot(kind='hist')\n",
    "s.apply(lambda x: 0 if x <= 220 else 1).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[HEADER]\n",
    "val_df = val_df[HEADER]\n",
    "\n",
    "train_df.to_csv('./data/processed/train-data.tsv', sep='\\t', index=False, header=False)\n",
    "val_df.to_csv('./data/processed/valid-data.tsv', sep='\\t', index=False, header=False)\n",
    "test_df.to_csv('./data/processed/test-data.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tsv_row(tsv_row):\n",
    "    \"\"\"\n",
    "    This function assumes that the text has already been cleaned and tokenized. \n",
    "    \"\"\"\n",
    "    data = tf.decode_csv(tsv_row, record_defaults=HEADER_DEFAULTS, field_delim='\\t')\n",
    "    features = dict(zip(HEADER, data))\n",
    "    target = features.pop(TARGET_NAME)\n",
    "    # giving more weight to \"spam\" records are the are only 13% of the training set\n",
    "    # features[WEIGHT_COLUNM_NAME] =  tf.cond( tf.equal(target,'spam'), lambda: 6.6, lambda: 1.0 ) \n",
    "    features[WEIGHT_COLUNM_NAME] = tf.cond(tf.equal(target, '1'), lambda: 6.6, lambda: 1.0 )\n",
    "    return features, target\n",
    "\n",
    "def parse_label(label_string_tensor):\n",
    "    \"\"\"\n",
    "    Takes a tensor string containg the labeled class and returns a one-hot vector representation.\n",
    "    \"\"\"\n",
    "    table = tf.contrib.lookup.index_table_from_tensor(tf.constant(TARGET_LABELS))\n",
    "    return table.lookup(label_string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(files_name_pattern, mode=tf.estimator.ModeKeys.EVAL, \n",
    "                 skip_header_lines=0, \n",
    "                 num_epochs=1,\n",
    "                 batch_size=200):\n",
    "    \"\"\"\n",
    "    Input Function for tensorflow estimator. Returns the tensor features and \n",
    "    one-hot representation of the target class.\n",
    "    \"\"\"\n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "    \n",
    "    num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1\n",
    "    \n",
    "    buffer_size = 2 * batch_size + 1\n",
    "   \n",
    "    print(\"\\n\", \"* data input_fn:\")\n",
    "    print(\"===========================================\")\n",
    "    print(\"Input file(s): {}\".format(files_name_pattern))\n",
    "    print(\"Batch size: {}\".format(batch_size))\n",
    "    print(\"Epoch Count: {}\".format(num_epochs))\n",
    "    print(\"Mode: {}\".format(mode))\n",
    "    print(\"Thread Count: {}\".format(num_threads))\n",
    "    print(\"Shuffle: {}\".format(shuffle))\n",
    "    print(\"===========================================\", \"\\n\")\n",
    "\n",
    "    file_names = tf.matching_files(files_name_pattern)\n",
    "    dataset = data.TextLineDataset(filenames=file_names)\n",
    "    \n",
    "    dataset = dataset.skip(skip_header_lines)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "        \n",
    "    dataset = dataset.map(lambda tsv_row: parse_tsv_row(tsv_row), \n",
    "                          num_parallel_calls=num_threads)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.prefetch(buffer_size)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, target = iterator.get_next()\n",
    "    return features, parse_label(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text_feature): \n",
    "    \"\"\"\n",
    "    The text features will be transformed into a word id vector. \n",
    "    \n",
    "    in  ---> ['a misty ridge uprises from the surge <UNK> <UNK> ... <UNK>']\n",
    "    out ---> [27 39 40 41 42  1 43  0  0 ... 0]\n",
    "    \"\"\"\n",
    "    #with tf.device(\"/device:XLA_CPU:0\"):\n",
    "    CLS = tf.fill(tf.shape(text_feature), \"[CLS]\")\n",
    "    SEP = tf.fill(tf.shape(text_feature), \"[SEP]\")   \n",
    "    text_feature = tf.strings.join([CLS, text_feature, SEP], separator=' ')\n",
    "    # Load vocabolary lookup table to map word => word_id\n",
    "    vocab_table = tf.contrib.lookup.index_table_from_file(vocabulary_file=VOCAB_LIST_FILE, \n",
    "                                                          num_oov_buckets=1, default_value=-1)\n",
    "    # Split text to words -> this will produce sparse tensor with variable-lengthes (word count) entries\n",
    "    words = tf.string_split(text_feature)\n",
    "    # Convert sparse tensor to dense tensor by padding each entry to match the longest in the batch\n",
    "    dense_words = tf.sparse_tensor_to_dense(words, default_value=PAD_WORD)\n",
    "    # Convert word to word_ids via the vocab lookup table\n",
    "    word_ids = vocab_table.lookup(dense_words)\n",
    "    # Create a word_ids padding\n",
    "    padding = tf.constant([[0,0],[0,MAX_DOCUMENT_LENGTH]])\n",
    "    # Pad all the word_ids entries to the maximum document length\n",
    "    word_ids_padded = tf.pad(word_ids, padding)\n",
    "    word_ids_padded = tf.dtypes.cast(word_ids_padded, dtype=tf.dtypes.int32)\n",
    "    word_id_vector = tf.slice(word_ids_padded, [0,0], [-1, MAX_DOCUMENT_LENGTH])\n",
    "    # Create Mask\n",
    "    input_mask = tf.where(word_id_vector > 0, tf.ones_like(word_id_vector, \n",
    "                                                           dtype=tf.dtypes.int32), word_id_vector)\n",
    "    # Create Seg IDs\n",
    "    segment_ids = tf.zeros(tf.shape(input_mask), dtype=tf.dtypes.int32)\n",
    "    # Return the final word_id_vector\n",
    "    return word_id_vector, input_mask, segment_ids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#mat = np.array([2,3,4,5,0,0,0,0], dtype=np.int32)\n",
    "#tf_mat = tf.constant(mat)\n",
    "#tf_mat = tf.where(tf_mat > 0, tf.ones_like(tf_mat), tf_mat)\n",
    "#zeros = tf.zeros(tf_mat.shape, dtype=tf.dtypes.int32)\n",
    "text_feature = tf.constant([\"test\", \"Test2\"])\n",
    "CLS = tf.fill(tf.shape(text_feature), \"[CLS]\")\n",
    "SEP = tf.fill(tf.shape(text_feature), \"[SEP]\")\n",
    "y = tf.strings.join([CLS, text_feature, SEP], separator=' ')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels, weights=None):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "    bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "        \n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            logits=logits, labels=labels, \n",
    "            weights=weights\n",
    "        )\n",
    "        #loss = tf.nn.weighted_cross_entropy_with_logits(labels, logits, pos_weight=weights)\n",
    "        return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    num_labels = params.num_labels\n",
    "    learning_rate = params.learning_rate\n",
    "    num_train_steps = params.num_train_steps\n",
    "    num_warmup_steps = params.num_warmup_steps\n",
    "\n",
    "    input_ids, input_mask, segment_ids  = process_text(features[\"comment_text\"])\n",
    "\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        is_predicting = True\n",
    "        \n",
    "        (predicted_labels, log_probs) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, labels, num_labels)\n",
    "        \n",
    "        predictions = {\n",
    "            'probabilities': log_probs,\n",
    "            'labels': predicted_labels\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          predictions=predictions, \n",
    "                                          export_outputs=export_outputs)\n",
    "    \n",
    "    else:\n",
    "        is_predicting = False\n",
    "        \n",
    "        # weights\n",
    "        weights = features[WEIGHT_COLUNM_NAME]\n",
    "        \n",
    "        (loss, predicted_labels, log_probs) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, labels, num_labels, weights=weights)\n",
    "\n",
    "        train_op = bert.optimization.create_optimizer(\n",
    "            loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "        # Calculate evaluation metrics.\n",
    "        def metric_fn(labels, predicted_labels, log_probs):\n",
    "            accuracy = tf.metrics.accuracy(labels, predicted_labels)\n",
    "            probs = tf.reduce_max(tf.exp(log_probs), axis=-1, keepdims=True)\n",
    "            f1_score = tf.contrib.metrics.f1_score(\n",
    "                labels,\n",
    "                probs)\n",
    "            return {\n",
    "                \"eval_accuracy\": accuracy,\n",
    "                \"f1_score\": f1_score,\n",
    "            }\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              train_op=train_op)\n",
    "        else:\n",
    "            eval_metrics = metric_fn(labels, predicted_labels, log_probs)\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                              loss=loss,\n",
    "                                              eval_metric_ops=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "TRAIN_SIZE = 1809000\n",
    "TOTAL_STEPS = int(TRAIN_SIZE / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "WARMUP_STEPS = int(TOTAL_STEPS * WARMUP_PROPORTION)\n",
    "EVAL_AFTER_SEC = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps is 43071. \n",
      "         Total number of warmup steps  is 4307.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Total number of steps is {0}. \n",
    "         Total number of warmup steps  is {1}.\"\"\".format(TOTAL_STEPS, WARMUP_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams  = tf.contrib.training.HParams(\n",
    "    num_epochs = NUM_TRAIN_EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_labels = len(TARGET_LABELS),\n",
    "    num_train_steps = TOTAL_STEPS,\n",
    "    num_warmup_steps = WARMUP_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    model_dir = OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "session_conf.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "session_conf.intra_op_parallelism_threads = multiprocessing.cpu_count()\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    session_config=session_conf,\n",
    "    log_step_count_steps=500,\n",
    "    save_checkpoints_steps=100,\n",
    "    tf_random_seed=17081992,\n",
    "    model_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    \"\"\"\n",
    "    Serving input function, should contain a receiver_tensor with the same features as the input during training, \n",
    "    this function will also be used during validation.\n",
    "    \"\"\"\n",
    "    receiver_tensor = {\n",
    "      'comment_text': tf.placeholder(tf.string, [None])\n",
    "    }\n",
    "    features = {\n",
    "      key: tensor\n",
    "      for key, tensor in receiver_tensor.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = lambda: input_fn(\n",
    "        TRAIN_DATA_FILES_PATTERN,\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "        num_epochs=NUM_TRAIN_EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    max_steps=hparams.num_train_steps,\n",
    "    hooks=None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = lambda: input_fn(\n",
    "        VALID_DATA_FILES_PATTERN,\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        batch_size=BATCH_SIZE\n",
    "    ),\n",
    "    exporters=[tf.estimator.LatestExporter( #LatestExporter or BestExporter\n",
    "        name=\"predict\", # the name of the folder in which the model will be exported to under export\n",
    "        serving_input_receiver_fn=serving_input_fn,\n",
    "        exports_to_keep=1,\n",
    "        as_text=True)],\n",
    "    steps=None,\n",
    "    throttle_secs = EVAL_AFTER_SEC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './toxic_models/', '_tf_random_seed': 17081992, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 40\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      "log_device_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: ON_1\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd71dcf470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:54.652136 139679930693440 estimator.py:201] Using config: {'_model_dir': './toxic_models/', '_tf_random_seed': 17081992, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 40\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      "log_device_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: ON_1\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 500, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd71dcf470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Type: <class 'tensorflow_estimator.python.estimator.estimator.Estimator'>\n"
     ]
    }
   ],
   "source": [
    "def create_estimator(run_config, hparams):\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                  params=hparams,\n",
    "                                  config=run_config)\n",
    "    print(\"Estimator Type: {}\".format(type(estimator)))\n",
    "    return estimator\n",
    "\n",
    "estimator = create_estimator(run_config, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started at 14:36:56\n",
      ".......................................\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.850668 139679930693440 estimator_training.py:185] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.855462 139679930693440 training.py:610] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.859523 139679930693440 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/train-*.tsv\n",
      "Batch size: 42\n",
      "Epoch Count: 1\n",
      "Mode: train\n",
      "Thread Count: 40\n",
      "Shuffle: True\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:56.958705 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:36:59.161143 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:08.497107 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:08.501667 139679930693440 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:10.198913 139679930693440 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-42976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:10.206092 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-42976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:14.249520 139679930693440 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:14.526021 139679930693440 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 42976 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:21.569036 139679930693440 basic_session_run_hooks.py:594] Saving checkpoints for 42976 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0675094, step = 42976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:37:48.065519 139679930693440 basic_session_run_hooks.py:249] loss = 0.0675094, step = 42976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 43071 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:14.345851 139679930693440 basic_session_run_hooks.py:594] Saving checkpoints for 43071 into ./toxic_models/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/valid-*.tsv\n",
      "Batch size: 42\n",
      "Epoch Count: 1\n",
      "Mode: eval\n",
      "Thread Count: 40\n",
      "Shuffle: False\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:16.991114 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:20.037435 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:28.100937 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-27T14:39:28Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:28.122597 139679930693440 evaluation.py:257] Starting evaluation at 2019-06-27T14:39:28Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:29.419227 139679930693440 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:29.427072 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:33.134473 139679930693440 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:33.414460 139679930693440 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-27-14:39:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.916481 139679930693440 evaluation.py:277] Finished evaluation at 2019-06-27-14:39:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 43071: eval_accuracy = 0.95844877, f1_score = 0.11991656, global_step = 43071, loss = 0.34091455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.924363 139679930693440 estimator.py:1979] Saving dict for global step 43071: eval_accuracy = 0.95844877, f1_score = 0.11991656, global_step = 43071, loss = 0.34091455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 43071: ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.927732 139679930693440 estimator.py:2039] Saving 'checkpoint_path' summary for global step 43071: ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:49.943537 139679930693440 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.793039 139679930693440 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.922961 139679930693440 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.935233 139679930693440 export.py:587] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.937599 139679930693440 export.py:587] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.939929 139679930693440 export.py:587] Signatures INCLUDED in export for Predict: ['prediction', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.942170 139679930693440 export.py:587] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:53.945685 139679930693440 export.py:587] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:54.192572 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-43071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:55.096708 139679930693440 builder_impl.py:654] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./toxic_models/export/predict/temp-b'1561646389'/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:55.099963 139679930693440 builder_impl.py:763] Assets written to: ./toxic_models/export/predict/temp-b'1561646389'/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./toxic_models/export/predict/temp-b'1561646389'/saved_model.pbtxt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:56.494462 139679930693440 builder_impl.py:414] SavedModel written to: ./toxic_models/export/predict/temp-b'1561646389'/saved_model.pbtxt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6736055.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:39:57.393692 139679930693440 estimator.py:359] Loss for final step: 0.6736055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................\n",
      "Experiment finished at 14:39:57\n",
      "\n",
      "Experiment elapsed time: 180.555674 seconds\n"
     ]
    }
   ],
   "source": [
    "#if not RESUME_TRAINING:\n",
    "#print(\"Removing previous artifacts...\")\n",
    "#shutil.rmtree(OUTPUT_DIR, ignore_errors=True)   \n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "time_start = datetime.utcnow() \n",
    "print(\"Experiment started at {}\".format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print(\".......................................\") \n",
    "\n",
    "import logging\n",
    "\n",
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('tensorflow.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "        estimator=estimator,\n",
    "        train_spec=train_spec, \n",
    "        eval_spec=eval_spec\n",
    ")\n",
    "\n",
    "time_end = datetime.utcnow() \n",
    "print(\".......................................\")\n",
    "print(\"Experiment finished at {}\".format(time_end.strftime(\"%H:%M:%S\")))\n",
    "print(\"\")\n",
    "time_elapsed = time_end - time_start\n",
    "print(\"Experiment elapsed time: {} seconds\".format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = val_df.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * data input_fn:\n",
      "===========================================\n",
      "Input file(s): data/processed/valid-*.tsv\n",
      "Batch size: 32\n",
      "Epoch Count: 1\n",
      "Mode: eval\n",
      "Thread Count: 40\n",
      "Shuffle: False\n",
      "=========================================== \n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:20.443544 139633935230784 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:22.440176 139633935230784 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:30.104430 139633935230784 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-26T12:06:30Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:30.123854 139633935230784 evaluation.py:257] Starting evaluation at 2019-06-26T12:06:30Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:31.273389 139633935230784 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:31.279703 139633935230784 saver.py:1270] Restoring parameters from ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:34.059045 139633935230784 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:06:34.331680 139633935230784 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [372/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:07:46.377252 139633935230784 evaluation.py:169] Evaluation [372/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [744/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:08:56.920406 139633935230784 evaluation.py:169] Evaluation [744/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1116/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:10:07.407554 139633935230784 evaluation.py:169] Evaluation [1116/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1488/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:11:17.899296 139633935230784 evaluation.py:169] Evaluation [1488/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1860/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:12:28.386068 139633935230784 evaluation.py:169] Evaluation [1860/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2232/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:13:38.859268 139633935230784 evaluation.py:169] Evaluation [2232/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2604/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:14:49.320812 139633935230784 evaluation.py:169] Evaluation [2604/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2976/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:15:59.776804 139633935230784 evaluation.py:169] Evaluation [2976/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3348/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:17:10.231661 139633935230784 evaluation.py:169] Evaluation [3348/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3720/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:20.713017 139633935230784 evaluation.py:169] Evaluation [3720/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3722/3722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.098714 139633935230784 evaluation.py:169] Evaluation [3722/3722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-26-12:18:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.491169 139633935230784 evaluation.py:277] Finished evaluation at 2019-06-26-12:18:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100000: eval_accuracy = 0.9622095, f1_score = 0.112007596, global_step = 100000, loss = 0.42697436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.494870 139633935230784 estimator.py:1979] Saving dict for global step 100000: eval_accuracy = 0.9622095, f1_score = 0.112007596, global_step = 100000, loss = 0.42697436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100000: ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 08:18:21.499738 139633935230784 estimator.py:2039] Saving 'checkpoint_path' summary for global step 100000: ./toxic_models/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Measures: {'eval_accuracy': 0.9622095, 'f1_score': 0.112007596, 'loss': 0.42697436, 'global_step': 100000}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = lambda: input_fn(files_name_pattern= VALID_DATA_FILES_PATTERN, \n",
    "                                      mode= tf.estimator.ModeKeys.EVAL,\n",
    "                                      batch_size= BATCH_SIZE)\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn, steps=steps)\n",
    "print(\"# Test Measures: {}\".format(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./toxic_models/export/predict/1561646389 \n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./toxic_models/export/predict/1561646389/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 10:45:48.735315 139679930693440 saver.py:1270] Restoring parameters from ./toxic_models/export/predict/1561646389/variables/variables\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "export_dir = \"./toxic_models/export/predict\"\n",
    "\n",
    "saved_model_dir = export_dir + \"/\" + os.listdir(path=export_dir)[-1] \n",
    "\n",
    "print(saved_model_dir, \"\\n\")\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "    export_dir = saved_model_dir,\n",
    "    signature_def_key=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cdebfc349d4329913919b30bb58fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=1805, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_result = val_df['comment_text'].swifter.apply(lambda text: predictor_fn({'comment_text': [text]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cd5232278d49408f1fd069d6253fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=97320, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_result = test_df['comment_text'].swifter.apply(lambda text: predictor_fn({'comment_text': [text]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([x['labels'] for x in val_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK] , please , please , could this des ##pic ##able sh ##rew just get lost in the woods and stay there .',\n",
       " '[UNK] to mention having the first openly gay player in [UNK] history : [UNK] [UNK] . . .',\n",
       " '\" [UNK] racism over brown people \" ? [UNK] 3d , now that is not [UNK] !',\n",
       " \"[UNK] respectful ##ly disagree ; it [UNK] a complex problem . [UNK] ' s why racism and big ##ot ##ry are as old as humanity itself . [UNK] , [UNK] do agree [UNK] cannot solve it ; he is incapable of solving any problems . [UNK] only make problems . [UNK] this case , it is [UNK] who has em ##bold ##ened the far right big ##ots and lifted the rock under which white su ##pre ##mac ##ists live . [UNK] ' re out and loud and are benefit ##ing from [UNK] ' s app ##all ##ing statements indicating a moral e ##qui ##vale ##ncy between white supremacy and social justice protests . [UNK] ' s absolutely disgusting that the [UNK] president behave ##s this way .\",\n",
       " '[UNK] do not sp ##ew a silly insult , [UNK] [UNK] [UNK] . [UNK] up all the evidence and make him eat his words .',\n",
       " '[UNK] all [UNK] are [UNK] . [UNK] in any form is evil .',\n",
       " '\" [UNK] \" ? [UNK] . [UNK] are more colors in my immediate family than in your entire voting district . [UNK] darkest - complexion ##ed among my family - - those of [UNK] , [UNK] , [UNK] and [UNK] descent - - would be most outraged to hear their peoples \\' struggles trivial ##ized by being compared to pathetic , bourgeois \" id ##eo ##logue ##s \" shriek ##ing and fl ##ailing about how their sexual practices should en ##ti ##tle them to special recognition .',\n",
       " 'the shoe would also fit using terms like \" dedicated \" \" strong believer \" . . do you like being called a trump vo ##tin w ##ha ##cko ? and still no source for the injuries - \" fake ##y news ##y \" on your part some might say - bull sh * t says [UNK]',\n",
       " '[UNK] ! \" [UNK] least [UNK] speaks the truth \" is the fun ##nies ##t thing [UNK] have ever heard by anyone describing a well - known , confirmed path ##ological liar . [UNK] is a potent drug . [UNK] people are addict ##s .',\n",
       " '[UNK] [UNK] women [UNK] [UNK] [UNK] [UNK] .',\n",
       " 'app whatever writes : \" [UNK] \\' t give us that crap about out of town ##ers coming here and dropping bucket ##s of money either . [UNK] does not happen . \" - [UNK] does . [UNK] do you think fills the restaurants every day , stays in the city for dinner and shops there ? [UNK] the retailers and restaurant owners if they think it is a good idea to discourage people from driving into [UNK] . [UNK] statement made out of ignorance .',\n",
       " '[UNK] camped in proximity to bear bait ##s myself for decades now without having any such problems , [UNK] would say [UNK] . [UNK] needs a dose of reality to go along with his ridiculous theory !',\n",
       " '[UNK] father had a saying : [UNK] in one hand and s * * t in the other and see which one gets full fastest .',\n",
       " '[UNK] , you are just repeating talking points , find the truth , [UNK] predict a huge swing away from the dem . party with the inner city voters , all citizens . [UNK] are getting fed up with being used and taken for granted , although there are still those who refuse to open their minds and look at results , preferring to just fall lock step in with hollow words spoken from their party leaders . http : / / www . ny ##time ##s . com / 2016 / 09 / 05 / us / politics / young - blacks - voice - skepticism - on - hillary - clinton - worrying - democrats . html ? _ r = 0 “ [UNK] am [UNK] supposed to do if [UNK] do not like him and [UNK] do not trust her ? ” a millennia ##l black woman in [UNK] asked . “ [UNK] between being stabbed and being shot ? [UNK] way ! ” “ [UNK] was part of the whole problem that started sending blacks to jail , ” a young black man , also from [UNK] , observed about [UNK] . [UNK] . “ [UNK] ’ s a racist , and she is a liar , so really what is the difference in choosing both or choosing neither ? ” another young black woman from [UNK] said .',\n",
       " \"[UNK] secret to negotiating with the [UNK] is to ignore the orange dump ##ster entirely , and get on with talks with the people that matter . [UNK] ' s like one of those in ##fl ##atable tubular clown ##s that you see on the roofs of car dealers ##hips : he waves back and forth and flaps his arms mania ##cal ##ly , but actually does precisely nothing .\",\n",
       " '[UNK] [UNK] was ridiculous yesterday of course , but [UNK] also enjoy seeing [UNK] progress and get better . [UNK] game . [UNK] [UNK] ! ! !',\n",
       " '[UNK] . [UNK] will not visit the [UNK] [UNK] of [UNK] because of all the angry white guys with guns .',\n",
       " \"[UNK] protesters supporting white nationalism - creepy . [UNK] who think en ##sl ##avi ##ng other humans is acceptable - creepy . [UNK] who think they are superior to women - creepy . [UNK] things those white men at the park support should be publicly denounced , and they should be humiliated . [UNK] is unacceptable and we need to fr ##ig ##gin ' say so , loudly .\",\n",
       " '[UNK] me get this straight . [UNK] \\' s lying h ##yp ##oc ##ris ##y is abs ##olved or somehow justified by [UNK] \\' s lies ? [UNK] ? [UNK] for the classic example of \" what ##ab ##out ##ism . \"',\n",
       " '[UNK] is described as \" bat s * * t insane \" blog favored by conspiracy theorists . [UNK] is published under pseudonym ##s so no one knows who actually writes it . [UNK] perfect for you , [UNK] .',\n",
       " '[UNK] in the shoes of a black man and perhaps you will understand .',\n",
       " \"[UNK] ' s some pretty fast bullet forensic ##s conducted [UNK] . [UNK] hope you are right about this guy . [UNK] wondered if there was a serial killer amongst us and based on this early report , this guy may have been a serial killer living amongst us . [UNK] damn scary is that ?\",\n",
       " '[UNK] hope they plan to pay the carbon tax , otherwise everything you have written is just white wash . [UNK] of course , how silly of me , they will be exempt .',\n",
       " \"bu ##rka sc ##hm ##ur ##ka ##how about a ban on muslim men pinch ##ing ladies ' bottoms in public places\",\n",
       " 'lobbying for the health [UNK] [UNK] [UNK] ? . [UNK] are these people ? [UNK] would even do that ? you are the bane of democracy . [UNK] hope my elected officials read this and know that we are not totally ignorant . 50 people need to go to jail .',\n",
       " '[UNK] dirty tag - team hit .',\n",
       " '[UNK] party harbor ##s the white su ##pre ##mist ##s and big ##ots , and some other fine people . . . . . . . . . . bon ##g , bon ##g , bon ##g , lo ##l',\n",
       " '[UNK] [UNK] said in a personal email to sheriff [UNK] , if he keeps his oath of office to defend the [UNK] against [UNK] enemies , foreign [UNK] [UNK] , and stands firm in the authority of his office and his commitment to protecting the rights of his [UNK] , the \" patriots \" will be at his command whether he says stay out or come help me . [UNK] , if he fails to keep his oath be it intentional or out of ignorance , the people will be [UNK] [UNK] [UNK] to continue listening to him . [UNK] - [UNK] [UNK] [UNK] [UNK] [UNK] on the [UNK] and [UNK] \" [UNK] \" , and stop ##making ignorant statements that make you sound like an idiot and a sub ##ser ##vie ##nt boot licking slave of an ##op ##pressive , out of control federal corporation , est . in 1871 and calling itself \" [UNK] [UNK] [UNK] \" ( see [UNK] [UNK] , [UNK] 28 , 300 ##2 , 15 ( a ) and look up this corporation on [UNK] and [UNK] , and also seen ##ot 1 but 2 [UNK] [UNK] [UNK] cases that acknowledge this non - constitutional national corporate government .',\n",
       " '[UNK] ah ##ah ##hh ##ha ##aa ##ah ##ha ##aa ##ah ##ha ##a [UNK] fool only yourself with lies like that .',\n",
       " '[UNK] [UNK] writes : \" [UNK] [UNK] imp ##ea ##chment \\' fantasy is all over \" - [UNK] [UNK] do not actually want [UNK] imp ##ea ##ched . [UNK] want him to run again in 2020 . [UNK] duck . [UNK] he is imp ##ea ##ched then the [UNK] can run someone else in 2020 . [UNK] [UNK] are dar ##ned if they do , dar ##ned if they do not .',\n",
       " '[UNK] do not hate my leftist non friend . [UNK] i do not shoot , kill , stab , or wound . . . . in the name of [UNK] , [UNK] , [UNK] , [UNK] or any other man made deity . [UNK] words might hurt , but the truth sometimes does . [UNK] back to sucking on the public tee ##t [UNK] , it is at least something you are good at .',\n",
       " \"h ##yp ##oc ##ris ##y ? [UNK] ' s why he got arrested . . . no more , and no less than any one else .\",\n",
       " '[UNK] hope she immediately reported this threat to the authorities . [UNK] a kn ##uck ##le - dragging cr ##eti ##n of a man .',\n",
       " '\" [UNK] do not take me alive , crooked [UNK] [UNK] copper ! \"',\n",
       " '[UNK] , like [UNK] , are betting getting their names in the paper by spreading hatred . [UNK] sound like a real estate con ##man / \" reality \" [UNK] game show host turned politician .',\n",
       " '[UNK] is a great move by [UNK] considering the recent \" free speech \" cancellation by [UNK] [UNK] after they decided conservative speakers are not en ##ti ##tle to the first amendment . [UNK] , students are too stupid to understand conservative viewpoint ##s are counter - productive to the utopia ##n , socialist society academics dream about . . . because the [UNK] , [UNK] & [UNK] all went about it the wrong way , right ?',\n",
       " '[UNK] [UNK] should remember that there is a dead [UNK] for every mile of railway across [UNK] ! ! ! [UNK] stop writing garbage about our relationship . [UNK] is naive except [UNK] .',\n",
       " '[UNK] is literally blackmail ##ing the [UNK] [UNK] . [UNK] : if you give [UNK] full pardon ; then [UNK] will give you the secret info he gave me . [UNK] is a traitor against [UNK] & he has been a traitor for [UNK]',\n",
       " '[UNK] ! [UNK] just pa ##ve the whole fr ##ig ##gin town . [UNK] while they are at it , they can clear - cut all the parks around town and fill them up with site condo ##s . [UNK] , and pa ##ve over the [UNK] [UNK] . . . just think of all the parking ! ! ! !',\n",
       " '[UNK] , you could have stopped at \" [UNK] cannot think \" and had a statement that ##s 100 % accurate . [UNK] you put in a bunch of trash that proves you \" can not think \" .',\n",
       " '[UNK] [UNK] are far and way the most aggressive avoid ##ers of tax in the land . [UNK] one is dumb enough to put it in print as such shows how bra ##zen they have become . [UNK] in this country is at an all time low .',\n",
       " '[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] . . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] ! !',\n",
       " '[UNK] terror attacks you mean like [UNK] ? ? ? [UNK] are [UNK] [UNK] [UNK] , [UNK] said those are [UNK] , nothing to worry about there . . . # [UNK]',\n",
       " '[UNK] the h * * * is he ? [UNK] un ##qual ##ified family member .',\n",
       " '[UNK] said it ! [UNK] for you ! [UNK] are bull ##ies .',\n",
       " '[UNK] me with a spoon . [UNK] [UNK] it is politics all right , you are giving ta ##cit support to [UNK] [UNK] and his insulting policies . [UNK] a [UNK] , [UNK] find these corporate , shallow [UNK] pro hockey players being fe ##ted by [UNK] naive , pathetic , and an embarrassment . [UNK] different than the attitude of spectators who attended the 1936 [UNK] [UNK] .',\n",
       " '[UNK] did hear what he said and [UNK] do not agree with all of it . [UNK] disagree with his stance on global warming , bringing coal back , making [UNK] pay for the wall and right now [UNK] am not impressed with his [UNK] head pick . [UNK] , those issues are not why [UNK] voted for him . [UNK] voted for him due to his other views such as thinking of the [UNK] [UNK] first , rebuilding our crumbling infrastructure , protecting our border , his \" anti - global ##ism \" stance , stopping the fleeing corporations from leaving the [UNK] . [UNK] . and other things . [UNK] was more factual ##ly correct , but pretty much everything she said was not her own thought . [UNK] came off as a robot , a dec ##eptive liar and she via the [UNK] [UNK] are incredibly corrupt . [UNK] plan to keep red ##ist ##ri ##bu ##ting wealth to gain votes is a bunch of crap also ( look at her tax plan ) . [UNK] [UNK] supporters took / take [UNK] literally , but not seriously . [UNK] supporters take him seriously , but not literally . [UNK] wild ride is going to begin .',\n",
       " '[UNK] what are they showing courage against . [UNK] are they not showing courage for all the veterans who have over the years died for their country and the ideals that have kept this country strong . [UNK] is obviously not the first idiot president that we have had ( and he most surely will not be the last ) , but you players not respecting the flag & the anthem , let alone the veterans that fought and died for you to be absolute babies makes me very sad even admit [UNK] watch the [UNK]',\n",
       " '[UNK] can see why . [UNK] are not dumb ; they can see what [UNK] thinks of [UNK] [UNK] .',\n",
       " '[UNK] a writer trying to get some attention - anyone that looks at this is a score for [UNK] [UNK] who is trying to make his way in the new dar ##n world of journalism . [UNK] a rookie .',\n",
       " '[UNK] is a med ##io ##cre talent who turned her back on [UNK] when she left for [UNK] . [UNK] stood up the [UNK] [UNK] [UNK] and thanks to [UNK] [UNK] the show went on . [UNK] was caught lip sync ##ing the national anthem on [UNK] . [UNK] it benefits her to be an \" [UNK] woman \" . [UNK] the bar ##f bag . [UNK] thanks to a real talent : [UNK] [UNK] .',\n",
       " '[UNK] again . . . . [UNK] [UNK] [UNK] [UNK] [UNK] known as [UNK] continues to bring terror to the world . [UNK] of [UNK] and [UNK] - right ? ? [UNK] up [UNK] ! !',\n",
       " \"[UNK] matter how you slice it people are just crap full of hatred . [UNK] ' s always been this way and the internet just amp ##li ##fies this .\"]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[(~(val_df.target.values == predictions)) & (val_df.target == 0)].comment_text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array([x['probabilities'][0][1] for x in test_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'] = np.exp(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"./bert_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7097320</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7097321</td>\n",
       "      <td>0.102077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7097322</td>\n",
       "      <td>0.022385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7097323</td>\n",
       "      <td>0.006065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7097324</td>\n",
       "      <td>0.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7097325</td>\n",
       "      <td>0.000715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7097326</td>\n",
       "      <td>0.082860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7097327</td>\n",
       "      <td>0.192811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7097328</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7097329</td>\n",
       "      <td>0.001392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7097330</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7097331</td>\n",
       "      <td>0.167843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7097332</td>\n",
       "      <td>0.006723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7097333</td>\n",
       "      <td>0.002051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7097334</td>\n",
       "      <td>0.036402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7097335</td>\n",
       "      <td>0.132002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7097336</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7097337</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7097338</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7097339</td>\n",
       "      <td>0.900396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7097340</td>\n",
       "      <td>0.012515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7097341</td>\n",
       "      <td>0.019033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7097342</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7097343</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7097344</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7097345</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7097346</td>\n",
       "      <td>0.007376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7097347</td>\n",
       "      <td>0.014317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7097348</td>\n",
       "      <td>0.010767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7097349</td>\n",
       "      <td>0.011533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97290</th>\n",
       "      <td>7194610</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97291</th>\n",
       "      <td>7194611</td>\n",
       "      <td>0.033361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97292</th>\n",
       "      <td>7194612</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97293</th>\n",
       "      <td>7194613</td>\n",
       "      <td>0.005443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97294</th>\n",
       "      <td>7194614</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97295</th>\n",
       "      <td>7194615</td>\n",
       "      <td>0.021078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97296</th>\n",
       "      <td>7194616</td>\n",
       "      <td>0.006351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97297</th>\n",
       "      <td>7194617</td>\n",
       "      <td>0.013326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>7194618</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97299</th>\n",
       "      <td>7194619</td>\n",
       "      <td>0.026829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97300</th>\n",
       "      <td>7194620</td>\n",
       "      <td>0.002951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97301</th>\n",
       "      <td>7194621</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97302</th>\n",
       "      <td>7194622</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>7194623</td>\n",
       "      <td>0.004665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>7194624</td>\n",
       "      <td>0.999275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97305</th>\n",
       "      <td>7194625</td>\n",
       "      <td>0.999257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>7194626</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97307</th>\n",
       "      <td>7194627</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97308</th>\n",
       "      <td>7194628</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97309</th>\n",
       "      <td>7194629</td>\n",
       "      <td>0.009236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97310</th>\n",
       "      <td>7194630</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97311</th>\n",
       "      <td>7194631</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97312</th>\n",
       "      <td>7194632</td>\n",
       "      <td>0.005855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97313</th>\n",
       "      <td>7194633</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97314</th>\n",
       "      <td>7194634</td>\n",
       "      <td>0.000918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97315</th>\n",
       "      <td>7194635</td>\n",
       "      <td>0.012279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97316</th>\n",
       "      <td>7194636</td>\n",
       "      <td>0.002902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97317</th>\n",
       "      <td>7194637</td>\n",
       "      <td>0.962759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97318</th>\n",
       "      <td>7194638</td>\n",
       "      <td>0.109350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97319</th>\n",
       "      <td>7194639</td>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prediction\n",
       "0      7097320    0.002762\n",
       "1      7097321    0.102077\n",
       "2      7097322    0.022385\n",
       "3      7097323    0.006065\n",
       "4      7097324    0.001761\n",
       "5      7097325    0.000715\n",
       "6      7097326    0.082860\n",
       "7      7097327    0.192811\n",
       "8      7097328    0.003471\n",
       "9      7097329    0.001392\n",
       "10     7097330    0.003144\n",
       "11     7097331    0.167843\n",
       "12     7097332    0.006723\n",
       "13     7097333    0.002051\n",
       "14     7097334    0.036402\n",
       "15     7097335    0.132002\n",
       "16     7097336    0.006351\n",
       "17     7097337    0.000898\n",
       "18     7097338    0.000929\n",
       "19     7097339    0.900396\n",
       "20     7097340    0.012515\n",
       "21     7097341    0.019033\n",
       "22     7097342    0.001089\n",
       "23     7097343    0.000736\n",
       "24     7097344    0.002833\n",
       "25     7097345    0.002747\n",
       "26     7097346    0.007376\n",
       "27     7097347    0.014317\n",
       "28     7097348    0.010767\n",
       "29     7097349    0.011533\n",
       "...        ...         ...\n",
       "97290  7194610    0.000754\n",
       "97291  7194611    0.033361\n",
       "97292  7194612    0.004975\n",
       "97293  7194613    0.005443\n",
       "97294  7194614    0.003040\n",
       "97295  7194615    0.021078\n",
       "97296  7194616    0.006351\n",
       "97297  7194617    0.013326\n",
       "97298  7194618    0.002088\n",
       "97299  7194619    0.026829\n",
       "97300  7194620    0.002951\n",
       "97301  7194621    0.002418\n",
       "97302  7194622    0.000858\n",
       "97303  7194623    0.004665\n",
       "97304  7194624    0.999275\n",
       "97305  7194625    0.999257\n",
       "97306  7194626    0.004789\n",
       "97307  7194627    0.001318\n",
       "97308  7194628    0.004658\n",
       "97309  7194629    0.009236\n",
       "97310  7194630    0.000730\n",
       "97311  7194631    0.001134\n",
       "97312  7194632    0.005855\n",
       "97313  7194633    0.003142\n",
       "97314  7194634    0.000918\n",
       "97315  7194635    0.012279\n",
       "97316  7194636    0.002902\n",
       "97317  7194637    0.962759\n",
       "97318  7194638    0.109350\n",
       "97319  7194639    0.000819\n",
       "\n",
       "[97320 rows x 2 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
